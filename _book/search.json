[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "R Beginner’s Guide (Best Practices)",
    "section": "",
    "text": "Preface\nI taught my spouse how to program in R (she had no previous knowledge despite completing a degree in Statistics). She, like many of us, was often frustrated while learning. I emphasized the kindness and generosity of the R community who write free books and provide support on forums. But as I started recommending books alongside our personal lessons, I noticed there wasn’t a book meant for a specific audience: a complete beginner who wishes to learn by doing and in a way that avoids future frustration.\nSimply put, this book is a hands-on guide for your very first R projects."
  },
  {
    "objectID": "index.html#for-the-love-of-r",
    "href": "index.html#for-the-love-of-r",
    "title": "R Beginner’s Guide (Best Practices)",
    "section": "For the Love of R",
    "text": "For the Love of R\nWithout a code- and project-oriented data science course, many beginner analysts know only mathematical or methodological knowledge and how to start a program. They are bound to write invalid code. The resulting invalid output is especially demotivating for analysts, as their task is to analyse the data. They may have been exposed to R in a Statistics courses, but these courses typically focus on methods and potentially mathematics; not work-flow, project-management, and coding. Furthermore, Statistics has a reputation for being hard, especially on those who are learning the subject only because it is required in a non-mathematical program.\nAs a result, R has two completely different reputations. Among students in Statistics courses, it is often despised. Among those who use the tool for work, it is usually loved. The difference may be caused by students paying to learn R, and employees being paid. But employees also realize, once they use R day-to-day, that there is an amazing community of others who help each other. This book is also meant to play a small part in that community."
  },
  {
    "objectID": "01-record-each-step.html#lines-and-lists",
    "href": "01-record-each-step.html#lines-and-lists",
    "title": "1  Record (Each Step)",
    "section": "\n1.1 Lines and Lists",
    "text": "1.1 Lines and Lists\nOn your left in Rstudio (what is called the code source), you have numbers like below that represent lines of text or code:\n1   Some text\n2\n3\n4\n5\nA list in text can be made by first skipping a line, and then starting the next line with numbers followed by a period (.) which is then followed by a space, or by using a hyphen (-) followed by a space:\n1   Some text\n2\n3   1. Start of my list\n4\n5\nLines 1 to 5 will show in your document as:\nSome text\n\nStart of my list\n\n–\nTo create a list within a list, indent twice before using -. Hit tab to indent.\n1   Some text\n2\n3   1. Start of my list\n4           - List within my list\n5\nLines 1 to 5 will show in your document as:\nSome text\n\nStart of my list\n\nList within my list\n\n\n\n–\nA list is broken if there is an empty line and a subsequent line that is not indented twice.\n1   Some text\n2\n3   1. Start of my list\n4           - List within my list\n5\n6   This line breaks the list\n7           - Some line indented twice in my code source\nLines 1 to 7 will show in your document as:\nSome text\n\nStart of my list\n\nList within my list\n\n\n\nThis line breaks the list - Some line indented twice in my code source"
  },
  {
    "objectID": "01-record-each-step.html#code",
    "href": "01-record-each-step.html#code",
    "title": "1  Record (Each Step)",
    "section": "\n1.2 Code",
    "text": "1.2 Code\nCode cannot be written on lines like text. For example\n1   some_code\n2   \n3\nwill not work. Code has to be declared in one of two ways.\nDeclaring With Single Back-Ticks\nYou can insert code into your document using a single back-tick (the ` symbol) before and after:\n1   Here's `some_code` to be shown.\n2   \n3   \nTo run, R code needs an r after the first back-tick:\n1   Here's `r some_code` to be processed.\n2   \n3   \nFor example, the date can be added to a line of your document using\n1   This report was made on `r Sys.Date()`.\n2\n3\nLines 1 to 3 will show in your document as:\nThis report was made on 2025-03-05.\n\n\nDeclaring With Multiple Back-Ticks\nYou can insert multiple lines of code into your document using multiple back-ticks before and after:\n10    ```{r}\n11    some_code\n12    some_more_code\n14    ```\nThe ```{r} starts the R code chunk and the ``` ends the chunk.\nThe primary purpose of a code chunk is to contain multiple lines of code. We will get an error when preparing our document if we try to declare with single back-ticks like here:\n10    `r  \n11  \n12    Sys.Date()\n13\n14    Sys.Date()\n15\n16    `\nInstead we must write this as:\n10    ```{r}\n11    Sys.Date()\n12    Sys.Date()\n13    ```\nThe following will be the result of the above chunk in our document:\n\nSys.Date()\n\n[1] \"2025-03-05\"\n\nSys.Date()\n\n[1] \"2025-03-05\"\n\n\nWhen declaring code with chunks (multiple back-ticks), the document will show both the code and the result of the code and this can be customized. When declaring code with single back-ticks, the document will show only the result of the code and this cannot be customized.\nSince the back-ticks take effort to write, there is a shortcut to writing an empty code chunk: command-Shift-I on Mac or ctrl-Shift-I on Windows.\nSummary\nTo summarize, compared to declaring code with single back-ticks,\n\nChunks can contain multiple lines.\nChunks can show both the code and the result of the code. This is great for showing your work or explaining your code to readers. This flexible property lets you decide whether the chunk shows the code and the result, only one of the two, or neither."
  },
  {
    "objectID": "01-record-each-step.html#errors",
    "href": "01-record-each-step.html#errors",
    "title": "1  Record (Each Step)",
    "section": "\n1.3 Errors",
    "text": "1.3 Errors\nWhen code is not written correctly, errors and probably some frustration will follow. R errors are not known for being friendly; they are not kind enough to tell you what is wrong in a way that is easy to understand. When there is an error, you will see it in red text within the Console, which is a box on the bottom left quarter of RStudio (its default layout). The Console is where the code is processed and the result printed.\nThere are symbols we need to know to understand the Console:\n&gt; means the line of code processed\n+ means a line of code continuing from the last line\n[1] means the first element of the result of the processed code\n[n] means the n'th element of the result of the processed code\n[[1]]\n[1] means the first element in the first container of the result of the processed code\nWhen first learning R, the best way to understand errors is usually not through R’s error messages. The best way is by paying close attention to the code and every little detail: misspelling, capitalization, and punctuation.\nFor this reason we want to practice good strategies of writing code. Writing involves naming our own objects and functions. But before that, we should also name our files using a good strategy. For a quick guide on naming files, click here."
  },
  {
    "objectID": "01-record-each-step.html#links",
    "href": "01-record-each-step.html#links",
    "title": "1  Record (Each Step)",
    "section": "\n1.4 Links",
    "text": "1.4 Links\nTo add a clickable link that sends the user to a website, place the website address within inequality symbols &lt; … &gt;. For example: &lt;http://www2.stat.duke.edu/~rcs46/lectures_2015/01-markdown-git/slides/naming-slides/naming-slides.pdf&gt; gives us http://www2.stat.duke.edu/~rcs46/lectures_2015/01-markdown-git/slides/naming-slides/naming-slides.pdf\nTo make this a hyperlink, that is, a shorter, clickable link, write the clickable text (the text you want to the reader to see) in square brackets and the website address in round brackets like so [text-seen-by-reader](link). For example\n1   [File Naming Presentation by Jenny Bryan](http://www2.stat.duke.edu/~rcs46/lectures_2015/01-markdown-git/slides/naming-slides/naming-slides.pdf)\n2\n3\nLines 1 to 3 will show as:\nFile Naming Presentation by Jenny Bryan"
  },
  {
    "objectID": "01-record-each-step.html#keyboard-shortcuts",
    "href": "01-record-each-step.html#keyboard-shortcuts",
    "title": "1  Record (Each Step)",
    "section": "\n1.5 Keyboard Shortcuts",
    "text": "1.5 Keyboard Shortcuts\nRemember, if you are using Windows, use\n\n\nCtrl instead of command\n\n\nAlt instead of option\n\n\nShortcuts:\n\n\ncommand-Z: Undo (go back)\n\ncommand-shift-Z: Redo (go forward)\n\ncommand-Enter: Process line of code where | is blinking (consistently appearing and disappearing)\n\ncommand-option-C: Process current chunk\n\noption-shift-arrow_key: Highlight all to the direction of the arrow"
  },
  {
    "objectID": "02-start-organized.html#name-files",
    "href": "02-start-organized.html#name-files",
    "title": "2  Start (Organized)",
    "section": "Name Files",
    "text": "Name Files\nNow that we have covered how to write lines, we can start writing lines about the data, right? Not yet. Let’s make sure our files have the best names possible as that will help in later writing about the data.\n\n\n\n\n\n\nNote\n\n\n\nFile naming is useful even if you only have one file of data. Apart from its clarity, it prepares you for the future possibility of having multiples files of data. Data sent to an analyst is often updated and re-sent, at which time you may want to keep records of the old and new.\n\n\nDefinitions:\n\n_ is called underscore.\n- is called dash.\n\nUse _ as a separator, that is, to separate different characteristics of the file. Use - to separate parts within characteristics. For example,\nlesson-1_on-qmd_2022-02-18.qmd\nIf you have related files that you want to systematically process, then be systematic with the order of characteristics. For example,\nlesson-1_on-qmd_2022-02-18.qmd\nlesson-2_on-qmd_2022-02-19.qmd\nlesson-3_on-qmd_2022-02-20.qmd\nlesson-1_on-python_2022-02-20.qmd\nConsider how these files will look when ordered alphabetically in your operating system’s file manager (File Explorer on Window’s or Finder on Mac) if that is important to you. The above files will be ordered like so:\nlesson-1_on-qmd_2022-02-18.qmd\nlesson-1_on-ruby_2022-02-20.qmd\nlesson-2_on-qmd_2022-02-19.qmd\nlesson-3_on-qmd_2022-02-20.qmd\nIf the order of characteristics start with the most general, then the alphabetic ordering will be more appropriate:\non-qmd_lesson-1_2022-02-18.qmd\non-qmd_lesson-2_2022-02-19.qmd\non-qmd_lesson-3_2022-02-20.qmd\non-ruby_lesson-1_2022-02-20.qmd\nConsistency helps you visually process the files you see on your file explorer. It also helps when telling your computer how to process the files. We named the files using separators so that numeric information can be represented. That is, the phrase before the first _ is the first characteristic, the phrase before the second _ is the second characteristic and so on.\nTo process the file names in a way that splits these characteristics, we can use a function str_split() from an R package called stringr. File names are strings. Strings are character elements that cannot directly be treated numerically (they need to be converted into numeric elements first for that).\nTo use a function from a package, we first install the package by running\n\ninstall.packages(\"stringr\")\n\nDelete this line once you are done, as you will have no need to rerun (re-process) it.\nWe use a colon (the symbol :) twice to use a function from a package. If you write\n\nstringr::\n\nyou will see a drop-down menu of all the functions from stringr. str stands for string. Many function names start with str_. The drop-down menu from writing stringr:: adjusts when you add str_. For every function whose name starts with str_, the general purpose is the processing of strings. Similar to our file names above, the general part of the name comes first, then the _, and then the more specific purpose.\nThere are a few exceptions; some functions in stringr do not start with str_. But most start with str_ because str_ makes it clear what the function will process. This is important as we can avoid the need to write out stringr::. We avoid this by loading the package: making the function names in the package available. To load the package, run the following\n\nlibrary(stringr)\n\nNow when we only write str_, we still get a drop-down menu. To use a str_ function, we need some input strings."
  },
  {
    "objectID": "02-start-organized.html#bring-files-into-r",
    "href": "02-start-organized.html#bring-files-into-r",
    "title": "\n2  Start (Organized)\n",
    "section": "\n2.2 Bring Files Into R",
    "text": "2.2 Bring Files Into R\nLet’s get our consistent file names into R. We will use a function called file.choose().\n\n\n\n\n\n\nWhen referring to a function, () makes it crystal clear that the object has arguments, or in other words, inputs. () means either\n\nthe function is used with its default arguments, or\nthe function is just being referred to in text, as above.\n\n\n\n\nfile.choose() causes a pop-up that allows you to interactively search your computer files. If you are using Windows, this pop-up may unfortunately pop-up behind RStudio. You will need to Alt-Tab to find the pop-up. Once you see the pop-up, find the folder with your files and double click on (any) one of the files. The function will print the file path (the computer’s representation of where the file exists). Below we assign the file path to the object file_path.\n\nfile_path &lt;- file.choose()\n\nWe will now use a function path_dir() from the package fs. path_dir() will get the path of the directory from the file path. We will assign the result to the object directory_path.\n\nlibrary(fs)\ndirectory_path &lt;- path_dir(file_path)\n\nTo get a list of .csv files in this directory, we will use a list.files() function. This function has what are called two arguments. The first is the path to the folder that contains our files. The second is the pattern that is unique to the files we want.\n\nfiles &lt;- list.files(directory_path, pattern = \"csv\")\nfiles\n\n[1] \"gapminder_afganistan_2022-02-21.csv\" \n[2] \"gapminder_afghanistan_2022-02-21.csv\"\n[3] \"gapminder_canada_2022-02-21.csv\"     \n\n\nNow we use str_split() which will split our strings. For example,\n\nstr_split(files, \"_\")\n\n[[1]]\n[1] \"gapminder\"      \"afganistan\"     \"2022-02-21.csv\"\n\n[[2]]\n[1] \"gapminder\"      \"afghanistan\"    \"2022-02-21.csv\"\n\n[[3]]\n[1] \"gapminder\"      \"canada\"         \"2022-02-21.csv\"\n\n\nThis result is what is called a list. A list can contain anything. The [[1]] and [[2]] represent the first and second element of the list. The [1] indicates that the element to its very right is the first element.\nTo also separate the file type (.qmd) at the end, preceded by the period, we can adjust our function to separate by _ as well as ..\n\nstr_split(files, \"_.\")\n\n[[1]]\n[1] \"gapminder\"     \"fganistan\"     \"022-02-21.csv\"\n\n[[2]]\n[1] \"gapminder\"     \"fghanistan\"    \"022-02-21.csv\"\n\n[[3]]\n[1] \"gapminder\"     \"anada\"         \"022-02-21.csv\"\n\n\nWhat happened? This is not what we want, and it is because . is a special (i.e. meta) character. Special characters mean more to R than the literal symbol itself. The special character . represents any character. Hence we told str_split() to use _. as a separator which meant that _A was used as the first separator, and _2 as the second separator. We need to use different special characters to overcome this challenge: [ and ]. These square brackets can be used to surround the distinct characters that str_split will use as separators: [_.] will tell str_split() to use either a _ or a literal . as the separator.\n\nstr_split(files, \"[_.]\")\n\n[[1]]\n[1] \"gapminder\"  \"afganistan\" \"2022-02-21\" \"csv\"       \n\n[[2]]\n[1] \"gapminder\"   \"afghanistan\" \"2022-02-21\"  \"csv\"        \n\n[[3]]\n[1] \"gapminder\"  \"canada\"     \"2022-02-21\" \"csv\"       \n\n\nWe can have a cleaner result using str_split_fixed(). It is called “fixed” as we can fix the number of splits or pieces. We will split our strings into 4 pieces.\n\nstr_split_fixed(files, \"[_.]\", 4)\n\n     [,1]        [,2]          [,3]         [,4] \n[1,] \"gapminder\" \"afganistan\"  \"2022-02-21\" \"csv\"\n[2,] \"gapminder\" \"afghanistan\" \"2022-02-21\" \"csv\"\n[3,] \"gapminder\" \"canada\"      \"2022-02-21\" \"csv\"\n\n\nThis result is what is called a matrix. Let’s assign it to the object m.\n\nm &lt;- str_split_fixed(files, \"[_.]\", 4)\n\nNow we can see the matrix just by processing\n\nm\n\n     [,1]        [,2]          [,3]         [,4] \n[1,] \"gapminder\" \"afganistan\"  \"2022-02-21\" \"csv\"\n[2,] \"gapminder\" \"afghanistan\" \"2022-02-21\" \"csv\"\n[3,] \"gapminder\" \"canada\"      \"2022-02-21\" \"csv\"\n\n\nLet’s add informative names to the columns of the matrix. To do this, we use a function called colnames(). This function will be placed on the left of &lt;- as it is a replacement function. We replace the null (i.e. undefined) column names of our matrix with our list of characteristics.\n\ncolnames(m) &lt;- c(\"source\", \"country\", \"date\", \"file_type\")\nm\n\n     source      country       date         file_type\n[1,] \"gapminder\" \"afganistan\"  \"2022-02-21\" \"csv\"    \n[2,] \"gapminder\" \"afghanistan\" \"2022-02-21\" \"csv\"    \n[3,] \"gapminder\" \"canada\"      \"2022-02-21\" \"csv\"    \n\n\nLet’s create an object named df with a function called as_tibble() from the package tibble. What is a tibble? It is an R word for table. Remember to install tibble before running\n\nlibrary(tibble)\ndf &lt;- as_tibble(m)\ndf\n\n# A tibble: 3 × 4\n  source    country     date       file_type\n  &lt;chr&gt;     &lt;chr&gt;       &lt;chr&gt;      &lt;chr&gt;    \n1 gapminder afganistan  2022-02-21 csv      \n2 gapminder afghanistan 2022-02-21 csv      \n3 gapminder canada      2022-02-21 csv      \n\n\n\n\n\n\n\n\nWe now need the file path for each of our files. To list the files in our directory, use the function dir_ls(). Assign the result to object file_paths.\n\nfile_paths &lt;- dir_ls(directory_path)\n\nWe will now change our tibble so that there is a new column called file_path that contains our file_paths. To do this, we will use a function from the package dplyr (pronounced “data plier”). The function we will use is named after another word for change: mutate(). This function has two arguments. The first is the tibble. The second is the name of the new column, an equal sign, and the values we want in that column.\n\nlibrary(dplyr)\ndf &lt;- mutate(df, file_path = file_paths)"
  },
  {
    "objectID": "02-start-organized.html#bring-data-into-r",
    "href": "02-start-organized.html#bring-data-into-r",
    "title": "\n2  Start (Organized)\n",
    "section": "\n2.3 Bring Data Into R",
    "text": "2.3 Bring Data Into R\nWe can read in the data related to each file with the help of the file_path column. Not only that, we can read in the data so that it is organized inside our tibble. In each row of our tibble, we will add each file’s data hidden in a little box or “nest”. These nests will go under a column called data.\nTo change our tibble so that there is a new column, we will again use mutate(). The first argument is the tibble, just like above. The second is the name of the new column (data), an equal sign, and the values we want in that column.\nSince the values in this column will be data sets, we need to put these data sets in containers. Where we see \"csv\" 3 times under file_type in our tibble, we will see \"&lt;S3: spec_tbl_df&gt;\" 3 times under data. The &lt; and &gt; mean container. The S3: spec_tbl_df means data frame (another word for data set).\nWe need to use a special function inside mutate() when creating our data column so that the values of the data column are containers. This special function is called map() from the package purrr. purrr is pronounced like a cat’s purr (the low vibrating sound of happiness) and it refers to purposeful programming with R.\nThe result of map() will always be containers. The number of containers will always be the same as the length of the first argument to map(). The second argument of map() is the function that will be applied to the first argument. To create the data column, the first argument will be the file_path, and the second argument will be a custom read function.\nThe read function below, read_csv_c(), uses a function called read_csv() from the package readr. read_csv() reads .csv files and determines what kind of columns are in the data (e.g. numeric or character). We will decide the kind of columns ourselves, so we need to prevent the function from doing so. col_types is the argument inside of read_csv() with a .default. We need to set the .default to be \"c\". \"c\" stands for character. Character is a safe default as it is the original format of the .csv data.\n\nlibrary(readr)\n\nread_csv_c &lt;- function(csv_file_path) read_csv(csv_file_path, col_types = c(.default = \"c\"))\n\nNow we use our new function to read in our data.\n\ndf &lt;- mutate(df, data = map(file_path, read_csv_c))\ndf\n\n# A tibble: 3 × 6\n  source    country     date       file_type file_path                data      \n  &lt;chr&gt;     &lt;chr&gt;       &lt;chr&gt;      &lt;chr&gt;     &lt;fs::path&gt;               &lt;named li&gt;\n1 gapminder afganistan  2022-02-21 csv       …ganistan_2022-02-21.csv &lt;spc_tbl_&gt;\n2 gapminder afghanistan 2022-02-21 csv       …hanistan_2022-02-21.csv &lt;spc_tbl_&gt;\n3 gapminder canada      2022-02-21 csv       …r_canada_2022-02-21.csv &lt;spc_tbl_&gt;\n\n\nWe no longer need the file_path column so we will select it to be removed by using the select() function.\n\ndf &lt;- select(df, - file_path)\n\nWe can open our containers or “nests” in data using the function unnest() from the package tidyr.\n\nlibrary(tidyr)\ndf &lt;- unnest(df, data)\ndf\n\n# A tibble: 24 × 9\n   source    country     date  file_type continent year  lifeExp pop   gdpPercap\n   &lt;chr&gt;     &lt;chr&gt;       &lt;chr&gt; &lt;chr&gt;     &lt;chr&gt;     &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt; &lt;chr&gt;    \n 1 gapminder afghanistan 2022… csv       Asia      1952  28.801  8425… 779.4453…\n 2 gapminder afghanistan 2022… csv       Asia      1957  30.332  9240… 820.8530…\n 3 gapminder afghanistan 2022… csv       Asia      1962  31.997  1026… 853.10071\n 4 gapminder afghanistan 2022… csv       Asia      1967  34.02   1153… 836.1971…\n 5 gapminder afghanistan 2022… csv       Asia      1972  36.088  1307… 739.9811…\n 6 gapminder afghanistan 2022… csv       Asia      1977  38.438  1488… 786.11336\n 7 gapminder afghanistan 2022… csv       Asia      1982  39.854  1288… 978.0114…\n 8 gapminder afghanistan 2022… csv       Asia      1987  40.822  1386… 852.3959…\n 9 gapminder afghanistan 2022… csv       Asia      1992  41.674  1631… 649.3413…\n10 gapminder afghanistan 2022… csv       Asia      1997  41.763  2222… 635.3413…\n# ℹ 14 more rows\n\n\nThis data looks clean but looks can be deceiving. Remember that we set the df object to be a tibble with as_tibble()? A tibble is not only a table in R, but a cleaner kind of table. It shows only 10 rows, and as many columns that can comfortably be displayed. The sizing of the table surrounds the data, like the header (top line) # A tibble: 24 x 9 tells you how many rows (24) and columns (9) there are. The footer (bottom line) tells you what is missing from the display.\nEven though this data is small (24 rows by 9 columns can be evaluated using our eyes), it is always best to practice techniques that are generalizable to both small and large data. Let’s check the data with code."
  },
  {
    "objectID": "02-start-organized.html#check-data",
    "href": "02-start-organized.html#check-data",
    "title": "\n2  Start (Organized)\n",
    "section": "\n2.4 Check Data",
    "text": "2.4 Check Data\nThe simplest way to start evaluating data is to check that the values under each column meet expectations. Since we created the first 4 columns using our file names, we can be sure that these 4 columns are clean. For the next column, continent, we expect values to be continents, capitalized, and spelled correctly. Instead of reading each line with our eyes, we can read each line with our computers. Or a combination of the two. That is exactly how we will start.\n\nunique(df$continent)\n\n[1] \"Asia\"     \"Americas\"\n\n\nThese unique values are perfect. Which means every value is perfect, as these unique values represent them. But what if they were not capitalized, for example? That is in fact the case with our country column: the values are not capitalized because the values came from our file-naming, and it is good practice not to capitalize when file-naming.\n\nunique(df$country)\n\n[1] \"afghanistan\" \"canada\""
  },
  {
    "objectID": "02-start-organized.html#clean-data",
    "href": "02-start-organized.html#clean-data",
    "title": "\n2  Start (Organized)\n",
    "section": "\n2.5 Clean Data",
    "text": "2.5 Clean Data\nTo capitalize the values in a column, you can use a function called str_to_title().\n\ndf &lt;- mutate(df, country = str_to_title(country))\ndf\n\n# A tibble: 24 × 9\n   source    country     date  file_type continent year  lifeExp pop   gdpPercap\n   &lt;chr&gt;     &lt;chr&gt;       &lt;chr&gt; &lt;chr&gt;     &lt;chr&gt;     &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt; &lt;chr&gt;    \n 1 gapminder Afghanistan 2022… csv       Asia      1952  28.801  8425… 779.4453…\n 2 gapminder Afghanistan 2022… csv       Asia      1957  30.332  9240… 820.8530…\n 3 gapminder Afghanistan 2022… csv       Asia      1962  31.997  1026… 853.10071\n 4 gapminder Afghanistan 2022… csv       Asia      1967  34.02   1153… 836.1971…\n 5 gapminder Afghanistan 2022… csv       Asia      1972  36.088  1307… 739.9811…\n 6 gapminder Afghanistan 2022… csv       Asia      1977  38.438  1488… 786.11336\n 7 gapminder Afghanistan 2022… csv       Asia      1982  39.854  1288… 978.0114…\n 8 gapminder Afghanistan 2022… csv       Asia      1987  40.822  1386… 852.3959…\n 9 gapminder Afghanistan 2022… csv       Asia      1992  41.674  1631… 649.3413…\n10 gapminder Afghanistan 2022… csv       Asia      1997  41.763  2222… 635.3413…\n# ℹ 14 more rows\n\n\nIt would be quite the task for this book to cover every method of checking and cleaning data. We covered the best-case scenario: the country column above was systematically unclean. Next, we show the worst-case scenario: manually entered text data. Later we show how to discover data validating and cleaning methods in ?sec-learn-as-you-go.\nThe next section is only for demonstrative purposes. Please see ?sec-text-data to prepare for actual text data methods."
  },
  {
    "objectID": "02-start-organized.html#remove-data",
    "href": "02-start-organized.html#remove-data",
    "title": "\n2  Start (Organized)\n",
    "section": "\n2.7 Remove Data",
    "text": "2.7 Remove Data\nfilter()\nIf we decide, after cleaning, that we don’t need parts of the data, should we remove files or edit the raw data? It’s often a better idea to keep a record of changes, with both code and comments. For example, to remove all but data on Asia, we can use filter().\n\n## Analysis is only on Asia\ndf_filtered &lt;- filter(df, continent == \"Asia\")\ndf_filtered\n\n# A tibble: 12 × 9\n   source    country     date  file_type continent year  lifeExp pop   gdpPercap\n   &lt;chr&gt;     &lt;chr&gt;       &lt;chr&gt; &lt;chr&gt;     &lt;chr&gt;     &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt; &lt;chr&gt;    \n 1 gapminder Afghanistan 2022… csv       Asia      1952  28.801  8425… 779.4453…\n 2 gapminder Afghanistan 2022… csv       Asia      1957  30.332  9240… 820.8530…\n 3 gapminder Afghanistan 2022… csv       Asia      1962  31.997  1026… 853.10071\n 4 gapminder Afghanistan 2022… csv       Asia      1967  34.02   1153… 836.1971…\n 5 gapminder Afghanistan 2022… csv       Asia      1972  36.088  1307… 739.9811…\n 6 gapminder Afghanistan 2022… csv       Asia      1977  38.438  1488… 786.11336\n 7 gapminder Afghanistan 2022… csv       Asia      1982  39.854  1288… 978.0114…\n 8 gapminder Afghanistan 2022… csv       Asia      1987  40.822  1386… 852.3959…\n 9 gapminder Afghanistan 2022… csv       Asia      1992  41.674  1631… 649.3413…\n10 gapminder Afghanistan 2022… csv       Asia      1997  41.763  2222… 635.3413…\n11 gapminder Afghanistan 2022… csv       Asia      2002  42.129  2526… 726.7340…\n12 gapminder Afghanistan 2022… csv       Asia      2007  43.828  3188… 974.5803…\n\n\ndistinct()\nWe can keep only unique (i.e. distinct) values under the a column using distinct(). It produces a tibble with only the distinct rows for the column(s) you choose. The argument .keep_all, if set to TRUE, keeps all columns. This can be seen in the help page: ?distinct.\n\ndistinct(select(df, country, continent), continent, .keep_all = TRUE)\n\n# A tibble: 2 × 2\n  country     continent\n  &lt;chr&gt;       &lt;chr&gt;    \n1 Afghanistan Asia     \n2 Canada      Americas"
  },
  {
    "objectID": "02-start-organized.html#code-concisely",
    "href": "02-start-organized.html#code-concisely",
    "title": "\n2  Start (Organized)\n",
    "section": "\n2.8 Code Concisely",
    "text": "2.8 Code Concisely\nWe can write the above in a more readable way using a special symbol.\n\ndf |&gt; \n  select(country, continent) |&gt; \n  distinct(continent, .keep_all = TRUE)\n\n# A tibble: 2 × 2\n  country     continent\n  &lt;chr&gt;       &lt;chr&gt;    \n1 Afghanistan Asia     \n2 Canada      Americas \n\n\nHow did that work?\n\n|&gt; and %&gt;%\n\n|&gt; and %&gt;% are called pipes and are used like so: left_side |&gt; right_side(). They send the left side to the right side. The |&gt; is newer and recommended because, where as the left side is an input, the right side is a function, and |&gt; enforces the () after the function name. Since |&gt; enforces an explicit and safer style, let’s stick with it.\nThe other property to remember is that the pipe holds mathematical priority before brackets and exponents. So if you know BEDMASS, then you also know BE|&gt;DMASS.\n\nsqrt(5) \n\n[1] 2.236068\n\n\nis the same as\n\n5 |&gt; sqrt()\n\n[1] 2.236068\n\n\nBut\n\n5 * 5 |&gt; sqrt()\n\n[1] 11.18034\n\n\nis not the same as\n\n(5 * 5) |&gt; sqrt()\n\n[1] 5\n\n\nFor a more relevant example,\n\ndf &lt;- mutate(df, year = as.numeric(year))\n\nis the same as\n\ndf &lt;- df |&gt; mutate(year = as.numeric(year))\n\nwhich is the same as\n\ndf &lt;- df |&gt; mutate(year = year |&gt; as.numeric())\n\nThe |&gt; is most useful to group together steps that accomplish a goal, e.g., summarizing data.\nsummarize()\nA few more functions allow for concise writing. summarize() is used to calculate a summary statistic.\n\n## Find the max year per country\ndf |&gt; summarize(max_year = max(year), .by = country) \n\n# A tibble: 2 × 2\n  country     max_year\n  &lt;chr&gt;          &lt;dbl&gt;\n1 Afghanistan     2007\n2 Canada          2007\n\n\nIt’s a short form for a number of other functions:\n\n## Find the max year per country\ndf |&gt; \n  group_by(country) |&gt; \n  mutate(max_year = max(year)) |&gt; \n  distinct(country, max_year)\n\n# A tibble: 2 × 2\n# Groups:   country [2]\n  country     max_year\n  &lt;chr&gt;          &lt;dbl&gt;\n1 Afghanistan     2007\n2 Canada          2007\n\n\nWe have not covered group_by() but we can see how it groups the data for the function(s) that follow it. Notice how the above data has a group.\ncount()\nThe last short form we will cover is count(). Instead of\n\ndf |&gt; summarize(n = n(), .by = country) \n\n# A tibble: 2 × 2\n  country         n\n  &lt;chr&gt;       &lt;int&gt;\n1 Afghanistan    12\n2 Canada         12\n\n\nyou can write\n\ndf |&gt; count(country)\n\n# A tibble: 2 × 2\n  country         n\n  &lt;chr&gt;       &lt;int&gt;\n1 Afghanistan    12\n2 Canada         12"
  },
  {
    "objectID": "03-learn-as-you-go.html#find-functions",
    "href": "03-learn-as-you-go.html#find-functions",
    "title": "3  Learn (As You Go)",
    "section": "\n3.1 Find Functions",
    "text": "3.1 Find Functions\nHow would you discover functions for your specific needs?\nBooks\nThere are many great books on R that will expose you to functions. But, if you learn best by doing, the most effective technical book will be the one designed toward your specific task.\nLarge-Language-Models\nThe hottest new method is to simply ask LLM’s.\nSearch Engines\nGoogle is a great search engine that most R programmers use when learning the R language. If we search “r capitalize first letter” we see, on 2025-03-05, the following paragraph as the first result:\n\nConvert First letter of every word to Uppercase in R Programming – str_to_title() Function. str_to_title() Function in R Language is used to convert the first letter of every word of a string to Uppercase and the rest of the letters are converted to lower case.\n\nThe trick is to, within Google, always write r before a question or the desired command, like how to capitalize first letter or simply capitalize first letter.\nThis is a simple example. Most of the time it can be difficult to write in English what you want. This will come with time and practice. At first you may find that the Google search results have nothing to do with what you need. That is a sign to re-word your search, or, if you’ve already re-worded your search, it may be a sign that there is no dedicated function for what you need, or that a different approach is needed. It’s rare that there will be no dedicated function so long as your goal is simple. You may find that it is effective to break down what you’re doing into simple steps, and then search for how to do those steps, as opposed to Googling something long and complicated, involving many steps.\nStack Overflow\nSpeaking of breaking down something complicated so that a search engine like Google can understand it, this is also necessary for others to understand it. For learning R, allowing others to understand your challenge or need is valuable as the R community is not only willing, but also quickly able to help. R users mainly help each other through Stack Overflow. It is a website that easily allows users to ask or answer questions with code, have their code formatted (look nice), and receive feedback.\nThe main draw of Stack Overflow is that the person asking the question has one main responsibility, and that is to produce what is called a minimally reproducible example: an example that can be used (reproduced) by someone else seeing the question, and that does not have unnecessary detail irrelevant to the question (minimal).\nDescribe example\nEXAMPLE HERE\nKnowing how to make an example is the majority of the work involved in asking a question on Stack Overflow.\nCreating Minimally Reproducible Examples\nIf your question involves data frames, you need to learn how to build a data frame before asking your question on Stack Overflow. To build a data frame, you can use the tibble() function from package tibble.\nIf you have 2 numeric columns, like in\n\n\n# A tibble: 12 × 2\n    year lifeExp\n   &lt;dbl&gt; &lt;chr&gt;  \n 1  1952 28.801 \n 2  1957 30.332 \n 3  1962 31.997 \n 4  1967 34.02  \n 5  1972 36.088 \n 6  1977 38.438 \n 7  1952 68.75  \n 8  1957 69.96  \n 9  1962 71.3   \n10  1967 72.13  \n11  1972 72.88  \n12  1977 74.21  \n\n\nthen the first part of your minimal example might look this:\n\ntibble(x = c(1, 2, 1, 2), y = c(3, 4, 2, 2))\n\n# A tibble: 4 × 2\n      x     y\n  &lt;dbl&gt; &lt;dbl&gt;\n1     1     3\n2     2     4\n3     1     2\n4     2     2\n\n\nAnd if what you’re trying to achieve is\n\n\n# A tibble: 6 × 2\n   year mean_lifeExp\n  &lt;dbl&gt;        &lt;dbl&gt;\n1  1952         48.8\n2  1957         50.1\n3  1962         51.6\n4  1967         53.1\n5  1972         54.5\n6  1977         56.3\n\n\nthen the second part of your minimal example might look like this:\n\ntibble(x = c(1, 2), mean_y = c(2.5, 2))\n\n# A tibble: 2 × 2\n      x mean_y\n  &lt;dbl&gt;  &lt;dbl&gt;\n1     1    2.5\n2     2    2  \n\n\nTo summarize, your entire question on Stack Overflow could look like this:\nHow can I transform the first tibble into the second tibble with a function?\nlibrary(tibble)\ntibble(x = c(1, 2, 1, 2), y = c(3, 4, 2, 2))\ntibble(x = c(1, 2), mean_y = c(2.5, 2))\nTo make your question even better, you can format your code by using the reprex function from the reprex package. The curly brackets are needed to tell reprex that you have multiple lines of code.\n\nlibrary(reprex)\nreprex(\n  {\n    library(tibble)\n    tibble(x = c(1, 2, 1, 2), y = c(3, 4, 2, 2))\n    tibble(x = c(1, 2), mean_y = c(2.5, 2))\n  }\n)\n\nFinally your question looks friendly:\nHow can I transform the first tibble into the second tibble with a function?\n\nlibrary(tibble)\ntibble(x = c(1, 2, 1, 2), y = c(3, 4, 2, 2))\n#&gt; # A tibble: 4 × 2\n#&gt;       x     y\n#&gt;   &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1     1     3\n#&gt; 2     2     4\n#&gt; 3     1     2\n#&gt; 4     2     2\ntibble(x = c(1, 2), mean_y = c(2.5, 2))\n#&gt; # A tibble: 2 × 2\n#&gt;       x mean_y\n#&gt;   &lt;dbl&gt;  &lt;dbl&gt;\n#&gt; 1     1    2.5\n#&gt; 2     2    2"
  },
  {
    "objectID": "03-learn-as-you-go.html#understand-functions",
    "href": "03-learn-as-you-go.html#understand-functions",
    "title": "3  Learn (As You Go)",
    "section": "\n3.2 Understand Functions",
    "text": "3.2 Understand Functions\nOnce you’ve found a function (or usually, a set of functions) recommended to you, it would be wise to understand how the function(s) work; specifically, the inputs and outputs.\nLarge-Language-Models\nLLM’s can explain function inputs and outputs as they are trained on public online knowledge.\nSearch Engines\nSearch engines will give a variety of websites. Remember, after googling “r capitalize first letter” we saw the following paragraph as the first result:\n\nConvert First letter of every word to Uppercase in R Programming – str_to_title() Function. str_to_title() Function in R Language is used to convert the first letter of every word of a string to Uppercase and the rest of the letters are converted to lower case.\n\nThis paragraph is from a website called GeeksforGeeks. I would not recommend using this website to understand the function. And for multiple reasons.\n\nYou are not familiar with the format of the website.\nYou will find yourself on multiple websites when you need to discover and learn about multiple functions.\nYou will then have to navigate the formats of these websites.\nMany things can get in the way of reading the instructions, like pop-ups to sign up for the website’s email list, advertisements for completely unrelated products (everything you need to learn R is FREE), and recommended articles to distract you.\n\nIt is more effective to use a single, standardized resource when learning about functions. Thankfully, R has a few.\nAfter reading the above paragraph and learning that the function we need may be str_to_title(), we can now Google search “r str_to_title” instead of “r capitalize first letter”. Again, Google shows multiple websites, but we are looking for one that is standardized. tidyverse.org is one of those websites, so we click the result that has “tidyverse.org” in the website address This brings us to this page: https://stringr.tidyverse.org/reference/case.html\nAs standard, there are multiple sections to the webpage describing a function: Usage, Arguments and Examples. Usage shows the format of the inputs to the function. Any input with an = beside it has a default value. A default value usually indicates that most users will not need to change the value.\nThe Usage str_to_title(string, locale = \"en\") tells us that\n\n\nstring should be an object containing some string(s) or a string itself. It has no default value; we must provide one.\n\nlocale has the default value \"en\".\n\nThe Arguments tell us more about the inputs in case the Usage is not enough. When first learning R, Arguments can be overwhelming; you might quickly find yourself not understanding the words contained therein, and having to continuously look up definitions (or more function documentation) in order to understand.\nStack Overflow\nAnother way to understand functions is to be presented with answers from others on Stack Overflow. These answers don’t need to be answers to the questions you have posted on Stack Overflow; they can be answers to questions posted by others.\nFor example, here is a question dated from 2019: https://stackoverflow.com/questions/58996293/transforming-a-dataframe-by-multiplying-a-columns-elements-by-the-names-of-th\nThere are three separate answers that have up votes (positive feedback represented by the digit on the top left of an answer): 1 using the data.table package; 1 using base R (R without packages); and 1 using tidyr.\nNotice how the answer using tidyr is far more simple; it is one line of code. This word tidy keeps popping up, and for good reason: the functions in this package and more broadly in the tidyverse (the tidy universe) are designed to make coding short and simple.\nIt is possible to add comments to the answers on Stack Overflow, with further questions about the functions if there is something you don’t understand. Fortunately the tidyverse functions are well documented because of their standardized webpages, and because of multiple, free books on using them for specific tasks."
  },
  {
    "objectID": "04-stay-organized.html",
    "href": "04-stay-organized.html",
    "title": "\n4  Review (to Stay Organized)\n",
    "section": "",
    "text": "Let’s say we need to read data in again, and we have named your files as per Section 2.1. To summarize, the file names have phrases with words separated by -, and multiple phrases are separated by _.\nInstead of copy-pasting the same code we used the previous time, we can avoid this repetition with a function. We can create this function by assigning function() to an object, and entering the inputs inside the () like so:\n\nsum &lt;- function(x, y) x + y\nsum(2, 2)\n\n[1] 4\n\n\nThe inputs of a function should be the parts of the function that change over repeated use. Since we want to repeat the code to read in data, but without being repetitive, our function will only contain inputs that are not repetitive. What part of reading our data is not repetitive now that we want to repeat the task for a set of different files.\nFor one, we can imagine that a new set of files might have a different number of phrases in the file names. So one input of our function can be n_phrases. Two, we can imagine that the phrases represent something different. Since we named them previously, let us call a second input of our function names_phrases.\nLastly, we need to name our function. The function name should reflect the main behaviour. If it is hard to identify the main behaviour, then it is probably best to split the function into multiple functions. Naming the functions appropriately is important for readability.\nLet us start by listing the behaviours of our function or functions:\n\nChoose a file\nFind the folder (directory) of this file\nFind the names of the csv files in this folder\nGet a matrix from splitting the phrases in each name\nName the columns and turn the matrix into a tibble\nFor each row representing a file, read its respective data into the tibble\n\nThat is a lot for one name to represent. Hence it is more prudent to separate these behaviours into multiple functions.\nCONTINUE HERE\nAlthough we could place all the code needed to read in data inside our function and name the function read_csv_in_df(), this is not a good idea. First, it is inconsistent with the popular function read_csv(), which has more than two arguments, the first of which is a file path.\nWith only two arguments, our function has the form function(n_phrases, names_phrases){code}. The code it will execute is in curly brackets {}. Although curly brackets were not needed in function(x, y) x + y, it will be needed here as the code will have multiple lines.\nAlthough we could place all the code needed to read in data inside and name the function read_csv_in_df(), then we would be acting without much care.\n\nread_csv_in_df &lt;- function(n_phrases, names_phrases){\n\n  one_file_path &lt;- file.choose()\n  directory_path &lt;- one_file_path |&gt; path_dir()\n  file_names &lt;- directory_path |&gt; list.files(pattern = \"csv\")\n  file_paths &lt;- directory_path |&gt; dir_ls()\n\n  split_matrix &lt;- file_names |&gt; str_split_fixed(\"[._]\", n_phrases)\n  colnames(split_matrix) &lt;- names_phrases\n\n  df &lt;- split_matrix |&gt;\n    as_tibble() |&gt;\n    mutate(data = map(file_paths, read_csv))\n\n  df\n\n}\n\n\n# read_csv_in_df\n\n\n# read_csv_in_df(4, c(\"source\", \"country\", \"date\" ,\"file_type\"))"
  },
  {
    "objectID": "05-text-data.html#patterns-and-regular-expressions-regexes",
    "href": "05-text-data.html#patterns-and-regular-expressions-regexes",
    "title": "Appendix A — Prepare for Text Data",
    "section": "A.1 Patterns and Regular Expressions (regexes)",
    "text": "A.1 Patterns and Regular Expressions (regexes)\nShort for regular expressions, regex (pronounced reg-ex) is a language for describing patterns in strings.\nLike any language, regex will appear foreign and difficult to understand without constantly looking up definitions for symbols. A good dictionary is the regex cheat sheet; search for “Regular Expressions” in https://www.rstudio.com/resources/cheatsheets/. The important definitions are in the left and bottom boxes.\nWhy learn this language? When do you need a language for describing patterns in strings?"
  },
  {
    "objectID": "05-text-data.html#motivation",
    "href": "05-text-data.html#motivation",
    "title": "Appendix A — Prepare for Text Data",
    "section": "A.2 Motivation",
    "text": "A.2 Motivation\nThe first definition under heading “Character Classes” in the regex cheatsheet is\n[[:digit:]] or \\\\d  Digits; [0-9]\nThis tells us that to represent digits in patterns, we can write \"[[:digit:]]\" or \"\\\\d\".\nWhen do we need patterns? Let’s say we want to make sure each row in the date column of our df has exactly 8 digits: 4 for the year, 2 for the month and 2 for the day. We cannot write the 8 digits directly, we need to represent them abstractly; that is the responsibility of patterns.\nThe pattern for digits is \"[[:digit:]]\" or \"\\\\d\". Now we need a pattern for “8 times”. We also cannot simply write 8, as we want to avoid representing the character 8. We now look for the abstract pattern representing “times”: or, in other words, “occurences”. On the bottom right, this pattern will be under the grey heading “Quantifiers”.\nThe 4th definition is\n{n}  Matches exactly n times\nThis tells us that to match 8 times, we can write \"{8}\".\nCombining what we learned about digits, we now write a pattern for digits 8 times: \"\\\\d{8}\".\nBefore using this pattern, let us try to understand each symbol. The \\\\ are needed to make sure that the pattern is not for the character “d” itself. Similarly, the { and } are needed to make sure that the pattern is not for the number “8” itself.\nIf we try to use our pattern to filter for dates with 8 digits, we get the following\n\ndf |&gt; filter(date |&gt; str_detect(\"\\\\d{8}\"))\n\n# A tibble: 0 × 9\n# ℹ 9 variables: source &lt;chr&gt;, country &lt;chr&gt;, date &lt;chr&gt;, file_type &lt;chr&gt;,\n#   continent &lt;chr&gt;, year &lt;dbl&gt;, lifeExp &lt;chr&gt;, pop &lt;chr&gt;, gdpPercap &lt;chr&gt;\n\n\n0 rows in our date column have digits exactly 8 times. How can that be?\nLooking back at our date column, what do we see?\n\ndf\n\n# A tibble: 24 × 9\n   source    country     date  file_type continent  year lifeExp pop   gdpPercap\n   &lt;chr&gt;     &lt;chr&gt;       &lt;chr&gt; &lt;chr&gt;     &lt;chr&gt;     &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt; &lt;chr&gt;    \n 1 gapminder Afghanistan 2022… csv       Asia       1952 28.801  8425… 779.4453…\n 2 gapminder Afghanistan 2022… csv       Asia       1957 30.332  9240… 820.8530…\n 3 gapminder Afghanistan 2022… csv       Asia       1962 31.997  1026… 853.10071\n 4 gapminder Afghanistan 2022… csv       Asia       1967 34.02   1153… 836.1971…\n 5 gapminder Afghanistan 2022… csv       Asia       1972 36.088  1307… 739.9811…\n 6 gapminder Afghanistan 2022… csv       Asia       1977 38.438  1488… 786.11336\n 7 gapminder Afghanistan 2022… csv       Asia       1982 39.854  1288… 978.0114…\n 8 gapminder Afghanistan 2022… csv       Asia       1987 40.822  1386… 852.3959…\n 9 gapminder Afghanistan 2022… csv       Asia       1992 41.674  1631… 649.3413…\n10 gapminder Afghanistan 2022… csv       Asia       1997 41.763  2222… 635.3413…\n# ℹ 14 more rows\n\n\ndate has 4 digits, followed by a hyphen, followed by 2 digits, followed by a hyphen, followed by 2 digits. Our pattern simply represents 8 digits, one after the other with nothing in between.\nIf we alter our pattern to \"\\\\d{4}-\\\\d{2}-\\\\d{2}\", we get the expected result:\n\ndf |&gt; filter(date |&gt; str_detect(\"\\\\d{4}-\\\\d{2}-\\\\d{2}\"))\n\n# A tibble: 24 × 9\n   source    country     date  file_type continent  year lifeExp pop   gdpPercap\n   &lt;chr&gt;     &lt;chr&gt;       &lt;chr&gt; &lt;chr&gt;     &lt;chr&gt;     &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt; &lt;chr&gt;    \n 1 gapminder Afghanistan 2022… csv       Asia       1952 28.801  8425… 779.4453…\n 2 gapminder Afghanistan 2022… csv       Asia       1957 30.332  9240… 820.8530…\n 3 gapminder Afghanistan 2022… csv       Asia       1962 31.997  1026… 853.10071\n 4 gapminder Afghanistan 2022… csv       Asia       1967 34.02   1153… 836.1971…\n 5 gapminder Afghanistan 2022… csv       Asia       1972 36.088  1307… 739.9811…\n 6 gapminder Afghanistan 2022… csv       Asia       1977 38.438  1488… 786.11336\n 7 gapminder Afghanistan 2022… csv       Asia       1982 39.854  1288… 978.0114…\n 8 gapminder Afghanistan 2022… csv       Asia       1987 40.822  1386… 852.3959…\n 9 gapminder Afghanistan 2022… csv       Asia       1992 41.674  1631… 649.3413…\n10 gapminder Afghanistan 2022… csv       Asia       1997 41.763  2222… 635.3413…\n# ℹ 14 more rows\n\n\nNow we not only checked that each row in date has 8 digits, but that theses digits are separated by hyphens in a XXXX-XX-XX format.\nWe still have not confirmed that the date column is in YYYY-MM-DD format (year-month-day format). This is unfortunately impossible for some cases. We cannot determine whether 02-04 is February 4nd or April 2nd unless we know whether the date was entered as MM-DD or DD-MM. Fortunately we can check cases where the day is greater than the 12th. We do so by checking whether the month in YYYY-MM-DD is between 01 and 12.\nTo do so we will adjust our pattern slightly so that month becomes a reference. To make a reference in a pattern, we surround the part we want to reference with round brackets: ( and ).\n\npattern &lt;- \"\\\\d{4}-(\\\\d{2})-\\\\d{2}\"\n\nTo extract the reference, we must refer to it by number. We need to use a number, as it is possible to have more than one reference group. Again we use \\\\ to make sure the pattern is not for the number “1” itself.\n\nreplacement &lt;- \"\\\\1\"\n\nWe now use our pattern and replacement in the function str_replace():\n\nmonth &lt;- \"2022-13-01\" |&gt; str_replace(pattern, replacement)\nmonth\n\n[1] \"13\"\n\n\nWe can treat this as numeric.\n\nmonth |&gt; as.numeric()\n\n[1] 13\n\n\nAnd then check whether it is above 12.\n\nmonth |&gt; as.numeric() &gt; 12\n\n[1] TRUE\n\n\nTo do this for every row of our data frame, we will create a month column, treat it as numeric, and filter by values greater than 12:\n\ndf &lt;- df |&gt; \n  mutate(month = date |&gt; str_replace(\"\\\\d{4}-(\\\\d{2})-\\\\d{2}\", \"\\\\1\") |&gt; as.numeric())\n\ndf |&gt; filter(month &gt; 12)\n\n# A tibble: 0 × 10\n# ℹ 10 variables: source &lt;chr&gt;, country &lt;chr&gt;, date &lt;chr&gt;, file_type &lt;chr&gt;,\n#   continent &lt;chr&gt;, year &lt;dbl&gt;, lifeExp &lt;chr&gt;, pop &lt;chr&gt;, gdpPercap &lt;chr&gt;,\n#   month &lt;dbl&gt;\n\n\nThere are no rows where month is greater than 12."
  },
  {
    "objectID": "05-text-data.html#understanding-representations",
    "href": "05-text-data.html#understanding-representations",
    "title": "Appendix A — Prepare for Text Data",
    "section": "A.3 Understanding Representations",
    "text": "A.3 Understanding Representations\nIf data contains characters like quotes and backslashes, R cannot directly represent them in a string. We can try to write each of these directly in a string and see what happens.\nQuotes:\n\n\"\"\"\n\nError: &lt;text&gt;:1:3: unexpected INCOMPLETE_STRING\n1: \"\"\"\n      ^\n\n\nR reads the first two set of quotes \"\" as an empty string, and considers the third set to be starting a second, incomplete string.\nBackslash:\n\n\"\\\"\n\nError: &lt;text&gt;:1:1: unexpected INCOMPLETE_STRING\n1: \"\\\"\n    ^\n\n\nThe backslash has a special behaviour, preventing the second \" from ending the string.\nSolution:\nSince R cannot represent quotes and backslash directly, it must instead represent them indirectly with special sequences of characters. For quotes, the representative sequence in R is \\\". For a backslash, the sequence is \\\\.\nWhen we place these sequences in strings, the output is not an error.\n\n\"\\\"\" \n\n[1] \"\\\"\"\n\n\n\n\"\\\\\"\n\n[1] \"\\\\\"\n\n\nFurther, we can see what each sequence represents by using the function writeLines():\n\n\"\\\"\" |&gt; writeLines()\n\n\"\n\n\n\n\"\\\\\" |&gt; writeLines()\n\n\\\n\n\nSequences \\\" and \\\\ start with a backslash because a backslash has a specific behaviour: it prevents the normal interpretation of the next character. The backslash in the string\"\\\"\" prevents the second quotes from being interpreted as the end of the string. As for the string \"\\\\\", because of the first backslash the second backslash is not normally interpreted as “preventing the normal interpretation of the next character”. Yes you will likely have to re-read that.\n\\\" and \\\\ are called special characters. Special characters are called special because they hold a special property: they each represent one thing (a unique character that cannot be represented directly). \\\" represents quotes, and \\\\ represents backslash. Scan the following list of special characters and what they represent.\n\n\n\nSpecial Characters\nRepresents\n\n\n\n\n\\n\nnewline\n\n\n\\r\ncarriage return\n\n\n\\t\ntab\n\n\n\\b\nbackspace\n\n\n\\a\nalert (bell)\n\n\n\\f\nform feed\n\n\n\\v\nvertical tab\n\n\n\\\\\nbackslash \\\n\n\n\\’\nASCII apostrophe ’\n\n\n\\”\nASCII quotation mark ”\n\n\n\\`\nASCII grave accent (backtick) `\n\n\n\nNotice how each has one backslash except for the case of \\\\. Again these special characters represent one thing. Representations of multiple things, however, have multiple backslashes (two to be exact). As an example, \\\\d represents multiple things because it represents any of the multiple digits from 0 to 9.\n\\\\ is a strange case. It is the only special character representing one thing with multiple backslashes. It is an even stranger case when used inside a pattern. We get an error:\n\npattern &lt;- \"\\\\\"\n\"\\\\\" |&gt; str_detect(\"\\\\\")\n\nError in stri_detect_regex(string, pattern, negate = negate, opts_regex = opts(pattern)): Unrecognized backslash escape sequence in pattern. (U_REGEX_BAD_ESCAPE_SEQUENCE, context=`\\`)\n\n\nAn error does not happen with any of the other special characters used in this way. The reason is that \\\\ is already used in patterns like \\\\d. If the pattern to match the string \"\\\\\" was simply \"\\\\\", representations like \\\\d would lose their meaning. For example, instead of matching digits, \\\\d would just match \\\\ followed by a d.\nTo match the string \"\\\\\" we must use the pattern \"\\\\\\\\\". To remember this, consider how R views four backslashes:\n\n\"\\\\\\\\\" |&gt; writeLines()\n\n\\\\"
  },
  {
    "objectID": "whats-possible.html",
    "href": "whats-possible.html",
    "title": "Appendix B — What’s Possible",
    "section": "",
    "text": "How to make your work reproducible using “R projects”\nHow to mask or randomize data in order ot make it public\nHow to build your own website\nHow to build tables (gt) and plots (ggplot)"
  },
  {
    "objectID": "02-start-organized.html#correspond-with-data-providers",
    "href": "02-start-organized.html#correspond-with-data-providers",
    "title": "2  Start (Organized)",
    "section": "Correspond With Data Providers",
    "text": "Correspond With Data Providers\nSuppose people answered a survey that included questions on how much time their children spend doing X on a typical day. These questions have two text boxes:\nUnique responses to the first box of the first question:\n\nx &lt;- c(\"5\", NA, \"3\", \"4\", \"2\", \"\",  \"1\", \"6\", \"8\", \"60\",  \"30\",  \"45\",  \"7\", \"20\", \n \"9\", \"35\",  \"3 \",  \"1.5\", \"4-5\", \"2 \",  \"40\", \n\"Day care\",\"3 to 4\", \"10\",  \"48\",  \"4hrs\",  \"15\",  \"90\", \n\"?\", \"12\")\nx\n\n [1] \"5\"        NA         \"3\"        \"4\"        \"2\"        \"\"        \n [7] \"1\"        \"6\"        \"8\"        \"60\"       \"30\"       \"45\"      \n[13] \"7\"        \"20\"       \"9\"        \"35\"       \"3 \"       \"1.5\"     \n[19] \"4-5\"      \"2 \"       \"40\"       \"Day care\" \"3 to 4\"   \"10\"      \n[25] \"48\"       \"4hrs\"     \"15\"       \"90\"       \"?\"        \"12\"      \n\n\nUnique responses to the second box which allows selection of the units:\n\nu &lt;- c(\"Minutes\", \"Hours\")\nu\n\n[1] \"Minutes\" \"Hours\"  \n\n\nEvidently this data needs to be cleaned before we do as.numeric() which turns non-numeric strings into NA.\nFirst, we might think, let’s deal with the interval responses like 4-5. We note there’s also a response 3 to 4. We can turn these responses into proper numbers like so:\n\nx1 &lt;- as.numeric(sub(\"^(.*?)(-|to).*\", \"\\\\1\", x))\n\nWarning: NAs introduced by coercion\n\nx2 &lt;- as.numeric(sub(\"^.*(-|to)(.*?)\", \"\\\\2\", x))\n\nWarning: NAs introduced by coercion\n\nifelse(grepl(\"-|to\", x), (x1+x2)/2, x)\n\n [1] \"5\"        NA         \"3\"        \"4\"        \"2\"        \"\"        \n [7] \"1\"        \"6\"        \"8\"        \"60\"       \"30\"       \"45\"      \n[13] \"7\"        \"20\"       \"9\"        \"35\"       \"3 \"       \"1.5\"     \n[19] \"4.5\"      \"2 \"       \"40\"       \"Day care\" \"3.5\"      \"10\"      \n[25] \"48\"       \"4hrs\"     \"15\"       \"90\"       \"?\"        \"12\"      \n\n\nNext we might think, let’s turn 4hrs into 4. But wouldn’t you want to know first that the units aren’t missing from the second box? And what’s Day care about? Does that mean “duration of day care”?\nBefore we start cleaning this data, converting units using the unit selected and slapping a pretty name like avg_day_active_play_time_hrs… human error needs to be considered. What if someone selected the wrong units? What sort of limits should we impose on plausible responses: e.g. is 16 hours the upper limit of a child’s active play time? After conversion to hours, do we then screen for &gt; 16 and turn those responses into minutes?\nThese are some of the questions one can ask before deciding to commit fully to cleaning this data. Clearly expert opinion is involved and that is where full transparency and leaving the data dirty might actually be best practice!"
  },
  {
    "objectID": "02-start-organized.html#check-with-your-team",
    "href": "02-start-organized.html#check-with-your-team",
    "title": "\n2  Start (Organized)\n",
    "section": "\n2.6 Check With Your Team",
    "text": "2.6 Check With Your Team\nSuppose people answered a survey that included questions on how much time their children spend doing X on a typical day. These questions have two text boxes:\nUnique responses to the first box of the first question:\n\nn &lt;- c(\"5\", NA, \"3\", \"4\", \"2\", \"\",  \"1\", \"6\", \"8\", \"60\",  \"30\",  \"45\",  \"7\", \"20\", \"9\", \"35\",  \"3 \",  \"1.5\", \"4-5\", \"2 \",  \"40\", \"Day care\", \"3 to 4\", \"10\",  \"48\",  \"4hrs\",  \"15\",  \"90\", \"?\", \"12\")\nn\n\n [1] \"5\"        NA         \"3\"        \"4\"        \"2\"        \"\"        \n [7] \"1\"        \"6\"        \"8\"        \"60\"       \"30\"       \"45\"      \n[13] \"7\"        \"20\"       \"9\"        \"35\"       \"3 \"       \"1.5\"     \n[19] \"4-5\"      \"2 \"       \"40\"       \"Day care\" \"3 to 4\"   \"10\"      \n[25] \"48\"       \"4hrs\"     \"15\"       \"90\"       \"?\"        \"12\"      \n\n\nUnique responses to the second box which allows selection of the units:\n\nunits &lt;- c(\"Minutes\", \"Hours\")\nunits\n\n[1] \"Minutes\" \"Hours\"  \n\n\nEvidently this data needs to be cleaned before we do as.numeric() which turns non-numeric strings into NA.\nFirst, we might think, let’s deal with the interval responses like 4-5. We note there’s also a response 3 to 4. We can turn these responses into proper numbers like so:\n\n## Don't worry about understanding the code here\nn1 &lt;- as.numeric(str_replace(n, \"^(.*?)(-|to).*\", \"\\\\1\"))\nn2 &lt;- as.numeric(str_replace(n, \"^.*(-|to)(.*?)\", \"\\\\2\"))\nifelse(str_detect(n, \"-|to\"), (n1+n2)/2, n)\n\n [1] \"5\"        NA         \"3\"        \"4\"        \"2\"        \"\"        \n [7] \"1\"        \"6\"        \"8\"        \"60\"       \"30\"       \"45\"      \n[13] \"7\"        \"20\"       \"9\"        \"35\"       \"3 \"       \"1.5\"     \n[19] \"4.5\"      \"2 \"       \"40\"       \"Day care\" \"3.5\"      \"10\"      \n[25] \"48\"       \"4hrs\"     \"15\"       \"90\"       \"?\"        \"12\"      \n\n\nNext we might think, let’s turn 4hrs into 4. But wouldn’t you want to know first that the units aren’t missing from the second box? And what’s Day care about? Does that mean “duration of day care”?\nBefore we start cleaning this data, converting units using the unit selected and slapping a pretty name like avg_day_play_time_hrs… human error needs to be considered. What if someone selected the wrong units? What sort of limits should we impose on plausible responses: e.g. is 16 hours the upper limit of a child’s active play time? After conversion to hours, do we then screen for &gt; 16 and turn those responses into minutes?\nThese are some of the questions one can ask before deciding to commit fully to cleaning this data. Holding off on cleaning to communicate with your team might be best practice. It may turn out that better methods of collecting data are enforced."
  },
  {
    "objectID": "02-start-organized.html#sec-name-files",
    "href": "02-start-organized.html#sec-name-files",
    "title": "\n2  Start (Organized)\n",
    "section": "\n2.1 Name Files",
    "text": "2.1 Name Files\nNow that we have covered how to write lines, we can start writing lines about the data, right? Not yet. Let’s make sure our files have the best names possible as that will help in later writing about the data.\n\n\n\n\n\n\nFile naming is useful even if you only have one file of data. Apart from its clarity, it prepares you for the future possibility of having multiples files of data. Data sent to an analyst is often updated and re-sent, at which time you may want to keep records of the old and new.\n\n\n\nDefinitions:\n\n\n_ is called underscore.\n\n- is called dash.\n\nUse _ as a separator, that is, to separate different characteristics of the file. Use - to separate parts within characteristics. For example,\nlesson-1_on-qmd_2022-02-18.qmd\nIf you have related files that you want to systematically process, then be systematic with the order of characteristics. For example,\nlesson-1_on-qmd_2022-02-18.qmd\nlesson-2_on-qmd_2022-02-19.qmd\nlesson-3_on-qmd_2022-02-20.qmd\nlesson-1_on-python_2022-02-20.qmd\nConsider how these files will look when ordered alphabetically in your operating system’s file manager (File Explorer on Window’s or Finder on Mac) if that is important to you. The above files will be ordered like so:\nlesson-1_on-qmd_2022-02-18.qmd\nlesson-1_on-ruby_2022-02-20.qmd\nlesson-2_on-qmd_2022-02-19.qmd\nlesson-3_on-qmd_2022-02-20.qmd\nIf the order of characteristics start with the most general, then the alphabetic ordering will be more appropriate:\non-qmd_lesson-1_2022-02-18.qmd\non-qmd_lesson-2_2022-02-19.qmd\non-qmd_lesson-3_2022-02-20.qmd\non-ruby_lesson-1_2022-02-20.qmd\nConsistency helps you visually process the files you see on your file explorer. It also helps when telling your computer how to process the files. We named the files using separators so that numeric information can be represented. That is, the phrase before the first _ is the first characteristic, the phrase before the second _ is the second characteristic and so on.\nTo process the file names in a way that splits these characteristics, we can use a function str_split() from an R package called stringr. File names are strings. Strings are character elements that cannot directly be treated numerically (they need to be converted into numeric elements first for that).\nTo use a function from a package, we first install the package by running\n\ninstall.packages(\"stringr\")\n\nDelete this line once you are done, as you will have no need to rerun (re-process) it.\nWe use a colon (the symbol :) twice to use a function from a package. If you write\n\nstringr::\n\nyou will see a drop-down menu of all the functions from stringr. str stands for string. Many function names start with str_. The drop-down menu from writing stringr:: adjusts when you add str_. For every function whose name starts with str_, the general purpose is the processing of strings. Similar to our file names above, the general part of the name comes first, then the _, and then the more specific purpose.\nThere are a few exceptions; some functions in stringr do not start with str_. But most start with str_ because str_ makes it clear what the function will process. This is important as we can avoid the need to write out stringr::. We avoid this by loading the package: making the function names in the package available. To load the package, run the following\n\nlibrary(stringr)\n\nNow when we only write str_, we still get a drop-down menu. To use a str_ function, we need some input strings."
  },
  {
    "objectID": "02-start-organized.html#sec-name_files",
    "href": "02-start-organized.html#sec-name_files",
    "title": "\n2  Start (Organized)\n",
    "section": "\n2.1 Name Files",
    "text": "2.1 Name Files\nNow that we have covered how to write lines, we can start writing lines about the data, right? Not yet. Let’s make sure our files have the best names possible as that will help in later writing about the data.\n\n\n\n\n\n\nFile naming is useful even if you only have one file of data. Apart from its clarity, it prepares you for the future possibility of having multiples files of data. Data sent to an analyst is often updated and re-sent, at which time you may want to keep records of the old and new.\n\n\n\nDefinitions:\n\n\n_ is called underscore.\n\n- is called dash.\n\nUse _ as a separator, that is, to separate different characteristics of the file. Use - to separate parts within characteristics. For example,\nlesson-1_on-qmd_2022-02-18.qmd\nIf you have related files that you want to systematically process, then be systematic with the order of characteristics. For example,\nlesson-1_on-qmd_2022-02-18.qmd\nlesson-2_on-qmd_2022-02-19.qmd\nlesson-3_on-qmd_2022-02-20.qmd\nlesson-1_on-python_2022-02-20.qmd\nConsider how these files will look when ordered alphabetically in your operating system’s file manager (File Explorer on Window’s or Finder on Mac) if that is important to you. The above files will be ordered like so:\nlesson-1_on-qmd_2022-02-18.qmd\nlesson-1_on-ruby_2022-02-20.qmd\nlesson-2_on-qmd_2022-02-19.qmd\nlesson-3_on-qmd_2022-02-20.qmd\nIf the order of characteristics start with the most general, then the alphabetic ordering will be more appropriate:\non-qmd_lesson-1_2022-02-18.qmd\non-qmd_lesson-2_2022-02-19.qmd\non-qmd_lesson-3_2022-02-20.qmd\non-ruby_lesson-1_2022-02-20.qmd\nConsistency helps you visually process the files you see on your file explorer. It also helps when telling your computer how to process the files. We named the files using separators so that numeric information can be represented. That is, the phrase before the first _ is the first characteristic, the phrase before the second _ is the second characteristic and so on.\nTo process the file names in a way that splits these characteristics, we can use a function str_split() from an R package called stringr. File names are strings. Strings are character elements that cannot directly be treated numerically (they need to be converted into numeric elements first for that).\nTo use a function from a package, we first install the package by running\n\ninstall.packages(\"stringr\")\n\nDelete this line once you are done, as you will have no need to rerun (re-process) it.\nWe use a colon (the symbol :) twice to use a function from a package. If you write\n\nstringr::\n\nyou will see a drop-down menu of all the functions from stringr. str stands for string. Many function names start with str_. The drop-down menu from writing stringr:: adjusts when you add str_. For every function whose name starts with str_, the general purpose is the processing of strings. Similar to our file names above, the general part of the name comes first, then the _, and then the more specific purpose.\nThere are a few exceptions; some functions in stringr do not start with str_. But most start with str_ because str_ makes it clear what the function will process. This is important as we can avoid the need to write out stringr::. We avoid this by loading the package: making the function names in the package available. To load the package, run the following\n\nlibrary(stringr)\n\nNow when we only write str_, we still get a drop-down menu. To use a str_ function, we need some input strings."
  },
  {
    "objectID": "04-stay-organized.html#folders",
    "href": "04-stay-organized.html#folders",
    "title": "\n4  Review (to Stay Organized)\n",
    "section": "\n4.1 Folders",
    "text": "4.1 Folders\nWe discussed how to optimally name data files in Section 2.1. We discussed how to write a Quarto report (a .qmd file) in Chapter 1. Should these sit in the same folder? For a small project, that can be adequate. However, it’s best to organize different kinds of files into different folders. This will help prevent confusion if and when our projects become large.\nGenerally, project files should be organized into the below folders:\n\n\ndata-raw (raw data files)\n\ndata (.R files that process raw data and create clean subsets)\n\nR_analysis (.R files that create analytic results)\n\nIf reporting, you should also have the following:\n\n\noutput (outputs that will be shared or used in reports; the latter can be the final objects in R_analysis saved as .rds)\n\nqmd (.qmd files which are Quarto reports)\n\nRmd (.Rmd files which are RMarkdown reports)\n\nOptionally:\n\n\nprose (references like Word documents, text files, etc.)"
  },
  {
    "objectID": "04-stay-organized.html#adjusting-workflow",
    "href": "04-stay-organized.html#adjusting-workflow",
    "title": "\n4  Review (to Stay Organized)\n",
    "section": "\n4.2 Adjusting Workflow",
    "text": "4.2 Adjusting Workflow\nWait a second… In Chapter 1 we processed raw data in a Quarto document, which would go inside the qmd folder. Above we are saying that raw data should be processed in .R files inside of the data folder. Why the change?\nIn fact, many analysts start their R journey using Quarto (or RMarkdown), including me. For Python users likewise, they often start with Jupyter. The ability to combine prose (written text), code, and outputs is beginner-friendly. It’s not, however, always computer-friendly. If code that processes data takes a moderate time to run, the report render will take at least this much time. If, instead, the code takes a short amount of time to run, because it does not process data beyond simply importing it, then the report render will be much, much faster."
  },
  {
    "objectID": "04-stay-organized.html#fast-data-reports",
    "href": "04-stay-organized.html#fast-data-reports",
    "title": "\n4  Review (to Stay Organized)\n",
    "section": "\n4.2 Fast Data Reports",
    "text": "4.2 Fast Data Reports\nMotivation\nIn Chapter 1 we processed raw data in a Quarto document, which would go inside the qmd folder. Above we are saying that raw data should be processed in .R files inside of the data folder. Why the change?\nTo be fair, many analysts start their R journey using Quarto (or RMarkdown), including me. For Python users likewise, they often start with Jupyter. The ability to combine prose (written text), code, and outputs is beginner-friendly. It’s not, however, always computer-friendly. If code that processes data takes a moderate time to run, the report render will take at least the same amount of time. If, instead, the code takes a short amount of time to run, because it does not process data beyond simply importing it, then the report render will be much, much faster.\nMethod\nIf we want fast reports, we want to simply import data and plots. We take out the data processing parts of our .qmd file and place them into an .R file (or multiple .R files) inside a new analysis folder. We name these .R files with the same philosophy as in Section 2.1: phrases separated by _, words in phrases separated by -. With several .R files, we add 0-padded numbers to the front of the file name. Here is an example:\n\n01_merge-data.R\n02_filter-data.R\n03_plot-data.R\n04_stat-analysis.R\n\nAny objects that we need for our report are saved using readr::write_rds(). The first two arguments are the object to write, and the file path (where to write it). The object can, for example, be a data file we want to display as a table in our report. The file path is going to refer to the new output folder. The best way to refer to files in this folder is to use the here package. here::here() is the function, and its name comes from the idea: “Here, I’m in this project, so let’s start at the file path to our project folder, i.e. the root folder.” Knowing this, here::here() simply takes strings that point to the location of any of our project’s files. For example, here::here(\"output\", \"data_for_table.rds\") will create a file path to the output folder ending with data_for_table.rds.\nFor example, we have a data file we want to display as a table, it will be saved somewhere in the above files with a line like write_rds(data_for_table, here(\"output\", \"data_for_table.rds\")).\nThen, in our .qmd file, we can simply add data_for_table &lt;- read_rds(here(\"output\", \"data_for_table.rds\")). Either load the readr library or prepend read_rds() with readr::.\nFinally, place the .qmd file into the qmd folder. Now we not only have a faster report, but our project is more organized."
  },
  {
    "objectID": "04-stay-organized.html#accessing-data",
    "href": "04-stay-organized.html#accessing-data",
    "title": "\n4  Review (to Stay Organized)\n",
    "section": "\n4.4 Accessing Data",
    "text": "4.4 Accessing Data\nIt’s a great idea to review how your getting raw data. If they are emailed .csv or .xlsx files, and especially if they have been manually edited or downloaded, there might be a better way to access data from the source. Accessing raw data from the source is more reliable and automatic. There’s less chance of a middle person between you and the data making a mistake and you having to re-run scripts with the corrections if the mistake even gets discovered! Also, you can get data without the limitations that come from waiting for a person to manage and deliver it.\nReviewing your strategy and improving it to allow for direct access may take more up-front work, but it usually will reduce future work. Another benefit is that learning to directly access data will up-skill you and further your career. You can learn software (data) engineering concepts like databases, API’s (Application Programming Interfaces), and more. These topics are beyond the scope of this book, but this section is here to encourage you to ask questions and learn more. A good book or large-language model can help introduce you to these topics. Once you become familiar with the lingo, you can start to incorporate database concepts with the following packages:\n\n\ndbplyr for lazy loading and computation (i.e. using the database server instead of your computer to hold data in memory and perform work)\n\nDBI for reading and writing to databases\n\ndm for data models (tables in your database and their relationships to each other)\n\nhttr2 for accessing API’s."
  },
  {
    "objectID": "04-stay-organized.html#making-your-own-functions",
    "href": "04-stay-organized.html#making-your-own-functions",
    "title": "\n4  Review (to Stay Organized)\n",
    "section": "\n4.3 Making Your Own Functions",
    "text": "4.3 Making Your Own Functions\nLet’s say we need to read data in again, and we have named your files as per Section 2.1. To summarize, the file names have phrases with words separated by -, and multiple phrases are separated by _.\nInstead of copy-pasting the same code we used the previous time, we can avoid this repetition with a function. We can create this function by assigning function() to an object, and entering the inputs inside the () like so:\n\nsum &lt;- function(x, y) x + y\nsum(2, 2)\n\n[1] 4\n\n\nThe inputs of a function should be the parts of the function that change over repeated use. Since we want to repeat the code to read in data, but without being repetitive, our function will only contain inputs that are not repetitive. What part of reading our data is not repetitive now that we want to repeat the task for a set of different files?\nFor one, we can imagine that a new set of files might have a different number of phrases in the file names. So one input of our function can be n_phrases. Two, we can imagine that the phrases represent something different. Since we named them previously, let us call a second input of our function names_phrases.\nLastly, we need to name our function. The function name should reflect the main behavior. If it is hard to identify the main behavior, then it is probably best to split the function into multiple functions. Naming the functions appropriately is important for readability.\nLet us start by listing the behaviors of our function or functions:\n\nChoose a file\nFind the folder (directory) of this file\nFind the names of the csv files in this folder\nGet a matrix from splitting the phrases in each name\nName the columns and turn the matrix into a tibble\nFor each row representing a file, read its respective data into the tibble\n\nThat is a lot for one name to represent. Hence it is more prudent to separate these behaviors into multiple functions."
  },
  {
    "objectID": "04-stay-organized.html#compare-your-functions-to-others",
    "href": "04-stay-organized.html#compare-your-functions-to-others",
    "title": "\n4  Review (to Stay Organized)\n",
    "section": "\n4.4 Compare Your Functions to Others",
    "text": "4.4 Compare Your Functions to Others\nAlthough we could place all the code needed to read in data inside our function and name the function read_csv_in_df(), this is not a good idea. It is inconsistent with the popular function read_csv(), which has more than two arguments, the first of which is a file path. This could confuse future readers (including future you).\nWith only two arguments, our function has the form function(n_phrases, names_phrases){code}. The code it will execute is in curly brackets {}. For function(x, y) x + y, we did not need the {} curly brackets. For our new function, they will be needed as the code will have multiple lines.\nWe could place all the code needed to read in data inside and name the function read_csv_in_df():\n\nread_csv_in_df &lt;- function(n_phrases, names_phrases){\n\n  one_file_path &lt;- file.choose()\n  directory_path &lt;- one_file_path |&gt; path_dir()\n  file_names &lt;- directory_path |&gt; list.files(pattern = \"csv\")\n  file_paths &lt;- directory_path |&gt; dir_ls()\n\n  split_matrix &lt;- file_names |&gt; str_split_fixed(\"[._]\", n_phrases)\n  colnames(split_matrix) &lt;- names_phrases\n\n  df &lt;- split_matrix |&gt;\n    as_tibble() |&gt;\n    mutate(data = map(file_paths, read_csv))\n\n  df\n\n}\n\n\n# read_csv_in_df\n\n\n# read_csv_in_df(4, c(\"source\", \"country\", \"date\" ,\"file_type\"))"
  },
  {
    "objectID": "04-stay-organized.html#optimal-access-of-data",
    "href": "04-stay-organized.html#optimal-access-of-data",
    "title": "\n4  Review (to Stay Organized)\n",
    "section": "\n4.2 Optimal Access of Data",
    "text": "4.2 Optimal Access of Data\nIt’s a great idea to review how your getting raw data. If they are emailed .csv or .xlsx files, and especially if they have been manually edited or downloaded, there might be a better way to access data from the source. Accessing raw data from the source is more reliable and automatic. There’s less chance of a middle person between you and the data making a mistake and you having to re-run scripts with the corrections if the mistake even gets discovered! Also, you can get data without the limitations that come from waiting for a person to manage and deliver it.\nReviewing your strategy and improving it to allow for direct access may take more up-front work, but it usually will reduce future work. Another benefit is that learning to directly access data will up-skill you and further your career. You can learn software (data) engineering concepts like databases, API’s (Application Programming Interfaces), and more. These topics are beyond the scope of this book, but this section is here to encourage you to ask questions and learn more. A good book or large-language model can help introduce you to these topics. Once you become familiar with the lingo, you can start to incorporate database concepts with the following packages:\n\n\ndbplyr for lazy loading and computation (i.e. using the database server instead of your computer to hold data in memory and perform work)\n\nDBI for reading and writing to databases\n\ndm for data models (tables in your database and their relationships to each other)\n\nhttr2 for data to and from API’s"
  },
  {
    "objectID": "04-stay-organized.html#optimal-workflow",
    "href": "04-stay-organized.html#optimal-workflow",
    "title": "\n4  Review (to Stay Organized)\n",
    "section": "\n4.1 Optimal Workflow",
    "text": "4.1 Optimal Workflow\nFolders\nWe discussed how to optimally name data files in Section 2.1. We discussed how to write a Quarto report (a .qmd file) in Chapter 1. Should these sit in the same folder? For a small project, that can be adequate. However, it’s best to organize different kinds of files into different folders. This will help prevent confusion if and when our projects become large. It can also dramatically speed up the rendering of our reports, which is covered in the next section.\nGenerally, project files should be organized into the below folders:\n\n\ndata-raw (raw data files)\n\ndata (.R files that process raw data and create clean subsets)\n\nR_analysis (.R files that create analytic results)\n\nIf reporting, you should also have the following:\n\n\noutput (outputs that will be shared or used in reports; the latter can be the final objects in R_analysis saved as .rds)\n\nqmd (.qmd files which are Quarto reports)\n\nRmd (.Rmd files which are RMarkdown reports)\n\nOptionally:\n\n\nprose (references like Word documents, text files, etc.)\nFast Data Reports\nMotivation\nIn Chapter 1 we processed raw data in a Quarto document, which would go inside the qmd folder. Above we are saying that raw data should be processed in .R files inside of the data folder. Why the change?\nTo be fair, many analysts start their R journey using Quarto (or RMarkdown), including me. For Python users likewise, they often start with Jupyter. The ability to combine prose (written text), code, and outputs is beginner-friendly. It’s not, however, always computer-friendly. If code that processes data takes a moderate time to run, the report render will take at least the same amount of time. If, instead, the code takes a short amount of time to run, because it does not process data beyond simply importing it, then the report render will be much, much faster.\nMethod\nIf we want fast reports, we want to simply import data and plots. We take out the data processing parts of our .qmd file and place them into an .R file (or multiple .R files) inside a new analysis folder. We name these .R files with the same philosophy as in Section 2.1: phrases separated by _, words in phrases separated by -. With several .R files, we add 0-padded numbers to the front of the file name. Here is an example:\n\n01_merge-data.R\n02_filter-data.R\n03_plot-data.R\n04_stat-analysis.R\n\nAny objects that we need for our report are saved using readr::write_rds(). The first two arguments are the object to write, and the file path (where to write it). The object can, for example, be a data file we want to display as a table in our report. The file path is going to refer to the new output folder. The best way to refer to files in this folder is to use the here package. here::here() is the function, and its name comes from the idea: “Here, I’m in this project, so let’s start at the file path to our project folder, i.e. the root folder.” Knowing this, here::here() simply takes strings that point to the location of any of our project’s files. For example, here::here(\"output\", \"data_for_table.rds\") will create a file path to the output folder ending with data_for_table.rds.\nFor example, we have a data file we want to display as a table, it will be saved somewhere in the above files with a line like write_rds(data_for_table, here(\"output\", \"data_for_table.rds\")).\nThen, in our .qmd file, we can simply add data_for_table &lt;- read_rds(here(\"output\", \"data_for_table.rds\")). Either load the readr library or prepend read_rds() with readr::.\nFinally, place the .qmd file into the qmd folder. Now we not only have a faster report, but our project is more organized."
  },
  {
    "objectID": "04-stay-organized.html#optimal-project-structure",
    "href": "04-stay-organized.html#optimal-project-structure",
    "title": "\n4  Review (to Stay Organized)\n",
    "section": "\n4.1 Optimal Project Structure",
    "text": "4.1 Optimal Project Structure\nWe discussed how to optimally name data files in Section 2.1. We discussed how to write a Quarto report (a .qmd file) in Chapter 1. Should these sit in the same folder? For a small project, that can be adequate. However, it’s best to organize different kinds of files into different folders. This will help prevent confusion if and when our projects become large. It can also dramatically speed up the rendering of our reports, which is covered in the next section.\nGenerally, project files should be organized into the below folders:\n\n\ndata-raw (raw data files)\n\ndata (.R files that process raw data and create clean subsets)\n\nR_analysis (.R files that create analytic results)\n\nIf reporting, you should also have the following:\n\n\noutput (outputs that will be shared or used in reports; the latter can be the final objects in R_analysis saved as .rds)\n\nqmd (.qmd files which are Quarto reports)\n\nRmd (.Rmd files which are RMarkdown reports)\n\nOptionally:\n\n\nprose (references like Word documents, text files, etc.)"
  },
  {
    "objectID": "04-stay-organized.html#optimal-data-access",
    "href": "04-stay-organized.html#optimal-data-access",
    "title": "\n4  Review (to Stay Organized)\n",
    "section": "\n4.3 Optimal Data Access",
    "text": "4.3 Optimal Data Access\nIt’s a great idea to review how your getting raw data. If they are emailed .csv or .xlsx files, and especially if they have been manually edited or downloaded, there might be a better way to access data from the source. Accessing raw data from the source is more reliable and automatic. There’s less chance of a middle person between you and the data making a mistake and you having to re-run scripts with the corrections if the mistake even gets discovered! Also, you can get data without the limitations that come from waiting for a person to manage and deliver it.\nReviewing your strategy and improving it to allow for direct access may take more up-front work, but it usually will reduce future work. Another benefit is that learning to directly access data will up-skill you and further your career. You can learn software (data) engineering concepts like databases, API’s (Application Programming Interfaces), and more. These topics are beyond the scope of this book, but this section is here to encourage you to ask questions and learn more. A good book or large-language model can help introduce you to these topics. Once you become familiar with the lingo, you can start to incorporate database concepts with the following packages:\n\n\ndbplyr for lazy loading and computation (i.e. using the database server instead of your computer to hold data in memory and perform work)\n\nDBI for reading and writing to databases\n\ndm for data models (tables in your database and their relationships to each other)\n\nhttr2 for data to and from API’s"
  },
  {
    "objectID": "04-stay-organized.html#optimal-code-maintanability",
    "href": "04-stay-organized.html#optimal-code-maintanability",
    "title": "\n4  Review (to Stay Organized)\n",
    "section": "\n4.4 Optimal Code Maintanability",
    "text": "4.4 Optimal Code Maintanability\nMaking Your Own Functions\nLet’s say we need to read data in again, and we have named your files as per Section 2.1. To summarize, the file names have phrases with words separated by -, and multiple phrases are separated by _.\nInstead of copy-pasting the same code we used the previous time, we can avoid this repetition with a function. We can create this function by assigning function() to an object, and entering the inputs inside the () like so:\n\nsum &lt;- function(x, y) x + y\nsum(2, 2)\n\n[1] 4\n\n\nThe inputs of a function should be the parts of the function that change over repeated use. Since we want to repeat the code to read in data, but without being repetitive, our function will only contain inputs that are not repetitive. What part of reading our data is not repetitive now that we want to repeat the task for a set of different files?\nFor one, we can imagine that a new set of files might have a different number of phrases in the file names. So one input of our function can be n_phrases. Two, we can imagine that the phrases represent something different. Since we named them previously, let us call a second input of our function names_phrases.\nLastly, we need to name our function. The function name should reflect the main behavior. If it is hard to identify the main behavior, then it is probably best to split the function into multiple functions. Naming the functions appropriately is important for readability.\nLet us start by listing the behaviors of our function or functions:\n\nChoose a file\nFind the folder (directory) of this file\nFind the names of the csv files in this folder\nGet a matrix from splitting the phrases in each name\nName the columns and turn the matrix into a tibble\nFor each row representing a file, read its respective data into the tibble\n\nThat is a lot for one name to represent. Hence it is more prudent to separate these behaviors into multiple functions.\nCompare Your Functions to Others\nAlthough we could place all the code needed to read in data inside our function and name the function read_csv_in_df(), this is not a good idea. It is inconsistent with the popular function read_csv(), which has more than two arguments, the first of which is a file path. This could confuse future readers (including future you).\nWith only two arguments, our function has the form function(n_phrases, names_phrases){code}. The code it will execute is in curly brackets {}. For function(x, y) x + y, we did not need the {} curly brackets. For our new function, they will be needed as the code will have multiple lines.\nWe could place all the code needed to read in data inside and name the function read_csv_in_df():\n\nread_csv_in_df &lt;- function(n_phrases, names_phrases){\n\n  one_file_path &lt;- file.choose()\n  directory_path &lt;- one_file_path |&gt; path_dir()\n  file_names &lt;- directory_path |&gt; list.files(pattern = \"csv\")\n  file_paths &lt;- directory_path |&gt; dir_ls()\n\n  split_matrix &lt;- file_names |&gt; str_split_fixed(\"[._]\", n_phrases)\n  colnames(split_matrix) &lt;- names_phrases\n\n  df &lt;- split_matrix |&gt;\n    as_tibble() |&gt;\n    mutate(data = map(file_paths, read_csv))\n\n  df\n\n}\n\n\n# read_csv_in_df\n\n\n# read_csv_in_df(4, c(\"source\", \"country\", \"date\" ,\"file_type\"))"
  },
  {
    "objectID": "04-stay-organized.html#optimal-reports",
    "href": "04-stay-organized.html#optimal-reports",
    "title": "\n4  Review (to Stay Organized)\n",
    "section": "\n4.2 Optimal Reports",
    "text": "4.2 Optimal Reports\nMotivation\nIn Chapter 1 we processed raw data in a Quarto document, which would go inside the qmd folder. Above we are saying that raw data should be processed in .R files inside of the data folder. Why the change?\nTo be fair, many analysts start their R journey using Quarto (or RMarkdown), including me. For Python users likewise, they often start with Jupyter. The ability to combine prose (written text), code, and outputs is beginner-friendly. It’s not, however, always computer-friendly. If code that processes data takes a moderate time to run, the report render will take at least the same amount of time. If, instead, the code takes a short amount of time to run, because it does not process data beyond simply importing it, then the report render will be much, much faster.\nMethod\nIf we want fast reports, we want to simply import data and plots. We take out the data processing parts of our .qmd file and place them into an .R file (or multiple .R files) inside a new analysis folder. We name these .R files with the same philosophy as in Section 2.1: phrases separated by _, words in phrases separated by -. With several .R files, we add 0-padded numbers to the front of the file name. Here is an example:\n\n01_merge-data.R\n02_filter-data.R\n03_plot-data.R\n04_stat-analysis.R\n\nAny objects that we need for our report are saved using readr::write_rds(). The first two arguments are the object to write, and the file path (where to write it). The object can, for example, be a data file we want to display as a table in our report. The file path is going to refer to the new output folder. The best way to refer to files in this folder is to use the here package. here::here() is the function, and its name comes from the idea: “Here, I’m in this project, so let’s start at the file path to our project folder, i.e. the root folder.” Knowing this, here::here() simply takes strings that point to the location of any of our project’s files. For example, here::here(\"output\", \"data_for_table.rds\") will create a file path to the output folder ending with data_for_table.rds.\nFor example, we have a data file we want to display as a table, it will be saved somewhere in the above files with a line like write_rds(data_for_table, here(\"output\", \"data_for_table.rds\")).\nThen, in our .qmd file, we can simply add data_for_table &lt;- read_rds(here(\"output\", \"data_for_table.rds\")). Either load the readr library or prepend read_rds() with readr::.\nFinally, place the .qmd file into the qmd folder. Now we not only have a faster report, but our project is more organized."
  },
  {
    "objectID": "04-stay-organized.html#optimal-less-confusing-file-folder-structure",
    "href": "04-stay-organized.html#optimal-less-confusing-file-folder-structure",
    "title": "\n4  Review (to Stay Organized)\n",
    "section": "\n4.1 Optimal (Less Confusing) File-Folder Structure",
    "text": "4.1 Optimal (Less Confusing) File-Folder Structure\nWe discussed how to optimally name data files in Section 2.1. We discussed how to write a Quarto report (a .qmd file) in Chapter 1. Should these sit in the same folder? For a small project, that can be adequate. However, it’s best to organize different kinds of files into different folders. This will help prevent confusion if and when our projects become large. It can also dramatically speed up the rendering of our reports, which is covered in the next section.\nGenerally, project files should be organized into the below folders:\n\n\ndata-raw (raw data files)\n\ndata (.R files that process raw data and create clean subsets)\n\nR_analysis (.R files that create analytic results)\n\nIf reporting, you should also have the following:\n\n\noutput (outputs that will be shared or used in reports; the latter can be the final objects in R_analysis saved as .rds)\n\nqmd (.qmd files which are Quarto reports)\n\nRmd (.Rmd files which are RMarkdown reports)\n\nOptionally:\n\n\nprose (references like Word documents, text files, etc.)"
  },
  {
    "objectID": "04-stay-organized.html#optimal-quicker-and-more-reliable-data-access",
    "href": "04-stay-organized.html#optimal-quicker-and-more-reliable-data-access",
    "title": "\n4  Review (to Stay Organized)\n",
    "section": "\n4.3 Optimal (Quicker and More Reliable) Data Access",
    "text": "4.3 Optimal (Quicker and More Reliable) Data Access\nIt’s a great idea to review how your getting raw data. If they are emailed .csv or .xlsx files, and especially if they have been manually edited or downloaded, there might be a better way to access data from the source. Accessing raw data from the source is more reliable and automatic. There’s less chance of a middle person between you and the data making a mistake and you having to re-run scripts with the corrections if the mistake even gets discovered! Also, you can get data without the limitations that come from waiting for a person to manage and deliver it.\nReviewing your strategy and improving it to allow for direct access may take more up-front work, but it usually will reduce future work. Another benefit is that learning to directly access data will up-skill you and further your career. You can learn software (data) engineering concepts like databases, API’s (Application Programming Interfaces), and more. These topics are beyond the scope of this book, but this section is here to encourage you to ask questions and learn more. A good book or large-language model can help introduce you to these topics. Once you become familiar with the lingo, you can start to incorporate database concepts with the following packages:\n\n\ndbplyr for lazy loading and computation (i.e. using the database server instead of your computer to hold data in memory and perform work)\n\nDBI for reading and writing to databases\n\ndm for data models (tables in your database and their relationships to each other)\n\nhttr2 for data to and from API’s"
  },
  {
    "objectID": "04-stay-organized.html#optimal-more-readable-and-maintanable-code",
    "href": "04-stay-organized.html#optimal-more-readable-and-maintanable-code",
    "title": "\n4  Review (to Stay Organized)\n",
    "section": "\n4.4 Optimal (More Readable and Maintanable) Code",
    "text": "4.4 Optimal (More Readable and Maintanable) Code\nMaking Your Own Functions\nLet’s say we need to read data in again, and we have named your files as per Section 2.1. To summarize, the file names have phrases with words separated by -, and multiple phrases are separated by _.\nInstead of copy-pasting the same code we used the previous time, we can avoid this repetition with a function. We can create this function by assigning function() to an object, and entering the inputs inside the () like so:\n\nsum &lt;- function(x, y) x + y\nsum(2, 2)\n\n[1] 4\n\n\nThe inputs of a function should be the parts of the function that change over repeated use. Since we want to repeat the code to read in data, but without being repetitive, our function will only contain inputs that are not repetitive. What part of reading our data is not repetitive now that we want to repeat the task for a set of different files?\nFor one, we can imagine that a new set of files might have a different number of phrases in the file names. So one input of our function can be n_phrases. Two, we can imagine that the phrases represent something different. Since we named them previously, let us call a second input of our function names_phrases.\nLastly, we need to name our function. The function name should reflect the main behavior. If it is hard to identify the main behavior, then it is probably best to split the function into multiple functions. Naming the functions appropriately is important for readability.\nLet us start by listing the behaviors of our function or functions:\n\nChoose a file\nFind the folder (directory) of this file\nFind the names of the csv files in this folder\nGet a matrix from splitting the phrases in each name\nName the columns and turn the matrix into a tibble\nFor each row representing a file, read its respective data into the tibble\n\nThat is a lot for one name to represent. Hence it is more prudent to separate these behaviors into multiple functions.\nCompare Your Functions to Others\nAlthough we could place all the code needed to read in data inside our function and name the function read_csv_in_df(), this is not a good idea. It is inconsistent with the popular function read_csv(), which has more than two arguments, the first of which is a file path. This could confuse future readers (including future you).\nWith only two arguments, our function has the form function(n_phrases, names_phrases){code}. The code it will execute is in curly brackets {}. For function(x, y) x + y, we did not need the {} curly brackets. For our new function, they will be needed as the code will have multiple lines.\nWe could place all the code needed to read in data inside and name the function read_csv_in_df():\n\nread_csv_in_df &lt;- function(n_phrases, names_phrases){\n\n  one_file_path &lt;- file.choose()\n  directory_path &lt;- one_file_path |&gt; path_dir()\n  file_names &lt;- directory_path |&gt; list.files(pattern = \"csv\")\n  file_paths &lt;- directory_path |&gt; dir_ls()\n\n  split_matrix &lt;- file_names |&gt; str_split_fixed(\"[._]\", n_phrases)\n  colnames(split_matrix) &lt;- names_phrases\n\n  df &lt;- split_matrix |&gt;\n    as_tibble() |&gt;\n    mutate(data = map(file_paths, read_csv))\n\n  df\n\n}\n\n\n# read_csv_in_df\n\n\n# read_csv_in_df(4, c(\"source\", \"country\", \"date\" ,\"file_type\"))"
  },
  {
    "objectID": "04-stay-organized.html#optimal-more-communicative-file-folder-structure",
    "href": "04-stay-organized.html#optimal-more-communicative-file-folder-structure",
    "title": "\n4  Review (to Stay Organized)\n",
    "section": "\n4.1 Optimal (More Communicative) File-Folder Structure",
    "text": "4.1 Optimal (More Communicative) File-Folder Structure\nWe discussed how to optimally name data files in Section 2.1. We discussed how to write a Quarto report (a .qmd file) in Chapter 1. Should these sit in the same folder? For a small project, that can be adequate. However, it’s best to organize different kinds of files into different folders. This will help prevent confusion if and when our projects become large. It can also dramatically speed up the rendering of our reports, which is covered in the next section.\nGenerally, project files should be organized into the below folders:\n\n\ndata-raw (raw data files)\n\ndata (.R files that process raw data and create clean subsets)\n\nR_analysis (.R files that create analytic results)\n\nIf reporting, you should also have the following:\n\n\noutput (outputs that will be shared or used in reports; the latter can be the final objects in R_analysis saved as .rds)\n\nqmd (.qmd files which are Quarto reports)\n\nRmd (.Rmd files which are RMarkdown reports)\n\nOptionally:\n\n\nprose (references like Word documents, text files, etc.)"
  },
  {
    "objectID": "04-stay-organized.html#optimal-more-speed-of-rendering-reports",
    "href": "04-stay-organized.html#optimal-more-speed-of-rendering-reports",
    "title": "\n4  Review (to Stay Organized)\n",
    "section": "\n4.2 Optimal (More Speed of Rendering) Reports",
    "text": "4.2 Optimal (More Speed of Rendering) Reports\nMotivation\nIn Chapter 1 we processed raw data in a Quarto document, which would go inside the qmd folder. Above we are saying that raw data should be processed in .R files inside of the data folder. Why the change?\nTo be fair, many analysts start their R journey using Quarto (or RMarkdown), including me. For Python users likewise, they often start with Jupyter. The ability to combine prose (written text), code, and outputs is beginner-friendly. It’s not, however, always computer-friendly. If code that processes data takes a moderate time to run, the report render will take at least the same amount of time. If, instead, the code takes a short amount of time to run, because it does not process data beyond simply importing it, then the report render will be much, much faster.\nMethod\nIf we want fast reports, we want to simply import data and plots. We take out the data processing parts of our .qmd file and place them into an .R file (or multiple .R files) inside a new analysis folder. We name these .R files with the same philosophy as in Section 2.1: phrases separated by _, words in phrases separated by -. With several .R files, we add 0-padded numbers to the front of the file name. Here is an example:\n\n01_merge-data.R\n02_filter-data.R\n03_plot-data.R\n04_stat-analysis.R\n\nAny objects that we need for our report are saved using readr::write_rds(). The first two arguments are the object to write, and the file path (where to write it). The object can, for example, be a data file we want to display as a table in our report. The file path is going to refer to the new output folder. The best way to refer to files in this folder is to use the here package. here::here() is the function, and its name comes from the idea: “Here, I’m in this project, so let’s start at the file path to our project folder, i.e. the root folder.” Knowing this, here::here() simply takes strings that point to the location of any of our project’s files. For example, here::here(\"output\", \"data_for_table.rds\") will create a file path to the output folder ending with data_for_table.rds.\nFor example, we have a data file we want to display as a table, it will be saved somewhere in the above files with a line like write_rds(data_for_table, here(\"output\", \"data_for_table.rds\")).\nThen, in our .qmd file, we can simply add data_for_table &lt;- read_rds(here(\"output\", \"data_for_table.rds\")). Either load the readr library or prepend read_rds() with readr::.\nFinally, place the .qmd file into the qmd folder. Now we not only have a faster report, but our project is more organized."
  },
  {
    "objectID": "04-stay-organized.html#optimal-more-reliable-data-access",
    "href": "04-stay-organized.html#optimal-more-reliable-data-access",
    "title": "\n4  Review (to Stay Organized)\n",
    "section": "\n4.3 Optimal (More Reliable) Data Access",
    "text": "4.3 Optimal (More Reliable) Data Access\nIt’s a great idea to review how your getting raw data. If they are emailed .csv or .xlsx files, and especially if they have been manually edited or downloaded, there might be a better way to access data from the source. Accessing raw data from the source is more reliable and automatic. There’s less chance of a middle person between you and the data making a mistake and you having to re-run scripts with the corrections if the mistake even gets discovered! Also, you can get data without the limitations that come from waiting for a person to manage and deliver it.\nReviewing your strategy and improving it to allow for direct access may take more up-front work, but it usually will reduce future work. Another benefit is that learning to directly access data will up-skill you and further your career. You can learn software (data) engineering concepts like databases, API’s (Application Programming Interfaces), and more. These topics are beyond the scope of this book, but this section is here to encourage you to ask questions and learn more. A good book or large-language model can help introduce you to these topics. Once you become familiar with the lingo, you can start to incorporate database concepts with the following packages:\n\n\ndbplyr for lazy loading and computation (i.e. using the database server instead of your computer to hold data in memory and perform work)\n\nDBI for reading and writing to databases\n\ndm for data models (tables in your database and their relationships to each other)\n\nhttr2 for data to and from API’s"
  },
  {
    "objectID": "04-stay-organized.html#optimal-more-maintanable-code",
    "href": "04-stay-organized.html#optimal-more-maintanable-code",
    "title": "\n4  Review (to Stay Organized)\n",
    "section": "\n4.4 Optimal (More Maintanable) Code",
    "text": "4.4 Optimal (More Maintanable) Code\nMaking Your Own Functions\nLet’s say we need to read data in again, and we have named your files as per Section 2.1. To summarize, the file names have phrases with words separated by -, and multiple phrases are separated by _.\nInstead of copy-pasting the same code we used the previous time, we can avoid this repetition with a function. We can create this function by assigning function() to an object, and entering the inputs inside the () like so:\n\nsum &lt;- function(x, y) x + y\nsum(2, 2)\n\n[1] 4\n\n\nThe inputs of a function should be the parts of the function that change over repeated use. Since we want to repeat the code to read in data, but without being repetitive, our function will only contain inputs that are not repetitive. What part of reading our data is not repetitive now that we want to repeat the task for a set of different files?\nFor one, we can imagine that a new set of files might have a different number of phrases in the file names. So one input of our function can be n_phrases. Two, we can imagine that the phrases represent something different. Since we named them previously, let us call a second input of our function names_phrases.\nLastly, we need to name our function. The function name should reflect the main behavior. If it is hard to identify the main behavior, then it is probably best to split the function into multiple functions. Naming the functions appropriately is important for readability.\nLet us start by listing the behaviors of our function or functions:\n\nChoose a file\nFind the folder (directory) of this file\nFind the names of the csv files in this folder\nGet a matrix from splitting the phrases in each name\nName the columns and turn the matrix into a tibble\nFor each row representing a file, read its respective data into the tibble\n\nThat is a lot for one name to represent. Hence it is more prudent to separate these behaviors into multiple functions.\nCompare Your Functions to Others\nAlthough we could place all the code needed to read in data inside our function and name the function read_csv_in_df(), this is not a good idea. It is inconsistent with the popular function read_csv(), which has more than two arguments, the first of which is a file path. This could confuse future readers (including future you).\nWith only two arguments, our function has the form function(n_phrases, names_phrases){code}. The code it will execute is in curly brackets {}. For function(x, y) x + y, we did not need the {} curly brackets. For our new function, they will be needed as the code will have multiple lines.\nWe could place all the code needed to read in data inside and name the function read_csv_in_df():\n\nread_csv_in_df &lt;- function(n_phrases, names_phrases){\n\n  one_file_path &lt;- file.choose()\n  directory_path &lt;- one_file_path |&gt; path_dir()\n  file_names &lt;- directory_path |&gt; list.files(pattern = \"csv\")\n  file_paths &lt;- directory_path |&gt; dir_ls()\n\n  split_matrix &lt;- file_names |&gt; str_split_fixed(\"[._]\", n_phrases)\n  colnames(split_matrix) &lt;- names_phrases\n\n  df &lt;- split_matrix |&gt;\n    as_tibble() |&gt;\n    mutate(data = map(file_paths, read_csv))\n\n  df\n\n}\n\n\n# read_csv_in_df\n\n\n# read_csv_in_df(4, c(\"source\", \"country\", \"date\" ,\"file_type\"))"
  },
  {
    "objectID": "04-stay-organized.html#optimal-more-quickly-rendered-reports",
    "href": "04-stay-organized.html#optimal-more-quickly-rendered-reports",
    "title": "\n4  Review (to Stay Organized)\n",
    "section": "\n4.2 Optimal (More Quickly Rendered) Reports",
    "text": "4.2 Optimal (More Quickly Rendered) Reports\nMotivation\nIn Chapter 1 we processed raw data in a Quarto document, which would go inside the qmd folder. Above we are saying that raw data should be processed in .R files inside of the data folder. Why the change?\nTo be fair, many analysts start their R journey using Quarto (or RMarkdown), including me. For Python users likewise, they often start with Jupyter. The ability to combine prose (written text), code, and outputs is beginner-friendly. It’s not, however, always computer-friendly. If code that processes data takes a moderate time to run, the report render will take at least the same amount of time. If, instead, the code takes a short amount of time to run, because it does not process data beyond simply importing it, then the report render will be much, much faster.\nMethod\nIf we want fast reports, we want to simply import data and plots. We take out the data processing parts of our .qmd file and place them into an .R file (or multiple .R files) inside a new analysis folder. We name these .R files with the same philosophy as in Section 2.1: phrases separated by _, words in phrases separated by -. With several .R files, we add 0-padded numbers to the front of the file name. Here is an example:\n\n01_merge-data.R\n02_filter-data.R\n03_plot-data.R\n04_stat-analysis.R\n\nAny objects that we need for our report are saved using readr::write_rds(). The first two arguments are the object to write, and the file path (where to write it). The object can, for example, be a data file we want to display as a table in our report. The file path is going to refer to the new output folder. The best way to refer to files in this folder is to use the here package. here::here() is the function, and its name comes from the idea: “Here, I’m in this project, so let’s start at the file path to our project folder, i.e. the root folder.” Knowing this, here::here() simply takes strings that point to the location of any of our project’s files. For example, here::here(\"output\", \"data_for_table.rds\") will create a file path to the output folder ending with data_for_table.rds.\nFor example, we have a data file we want to display as a table, it will be saved somewhere in the above files with a line like write_rds(data_for_table, here(\"output\", \"data_for_table.rds\")).\nThen, in our .qmd file, we can simply add data_for_table &lt;- read_rds(here(\"output\", \"data_for_table.rds\")). Either load the readr library or prepend read_rds() with readr::.\nFinally, place the .qmd file into the qmd folder. Now we not only have a faster report, but our project is more organized."
  },
  {
    "objectID": "04-stay-organized.html#optimal-file-folder-structure-more-communicative",
    "href": "04-stay-organized.html#optimal-file-folder-structure-more-communicative",
    "title": "\n4  Review (to Stay Organized)\n",
    "section": "\n4.1 Optimal File-Folder Structure (More Communicative)",
    "text": "4.1 Optimal File-Folder Structure (More Communicative)\nWe discussed how to optimally name data files in Section 2.1. We discussed how to write a Quarto report (a .qmd file) in Chapter 1. Should these sit in the same folder? For a small project, that can be adequate. However, it’s best to organize different kinds of files into different folders. This will help prevent confusion if and when our projects become large. It can also dramatically speed up the rendering of our reports, which is covered in the next section.\nGenerally, project files should be organized into the below folders:\n\n\ndata-raw (raw data files)\n\ndata (.R files that process raw data and create clean subsets)\n\nR_analysis (.R files that create analytic results)\n\nIf reporting, you should also have the following:\n\n\noutput (outputs that will be shared or used in reports; the latter can be the final objects in R_analysis saved as .rds)\n\nqmd (.qmd files which are Quarto reports)\n\nRmd (.Rmd files which are RMarkdown reports)\n\nOptionally:\n\n\nprose (references like Word documents, text files, etc.)"
  },
  {
    "objectID": "04-stay-organized.html#optimal-reports-more-quickly-rendered",
    "href": "04-stay-organized.html#optimal-reports-more-quickly-rendered",
    "title": "\n4  Review (to Stay Organized)\n",
    "section": "\n4.2 Optimal Reports (More Quickly Rendered)",
    "text": "4.2 Optimal Reports (More Quickly Rendered)\nMotivation\nIn Chapter 1 we processed raw data in a Quarto document, which would go inside the qmd folder. Above we are saying that raw data should be processed in .R files inside of the data folder. Why the change?\nTo be fair, many analysts start their R journey using Quarto (or RMarkdown), including me. For Python users likewise, they often start with Jupyter. The ability to combine prose (written text), code, and outputs is beginner-friendly. It’s not, however, always computer-friendly. If code that processes data takes a moderate time to run, the report render will take at least the same amount of time. If, instead, the code takes a short amount of time to run, because it does not process data beyond simply importing it, then the report render will be much, much faster.\nMethod\nIf we want fast reports, we want to simply import data and plots. We take out the data processing parts of our .qmd file and place them into an .R file (or multiple .R files) inside a new analysis folder. We name these .R files with the same philosophy as in Section 2.1: phrases separated by _, words in phrases separated by -. With several .R files, we add 0-padded numbers to the front of the file name. Here is an example:\n\n01_merge-data.R\n02_filter-data.R\n03_plot-data.R\n04_stat-analysis.R\n\nAny objects that we need for our report are saved using readr::write_rds(). The first two arguments are the object to write, and the file path (where to write it). The object can, for example, be a data file we want to display as a table in our report. The file path is going to refer to the new output folder. The best way to refer to files in this folder is to use the here package. here::here() is the function, and its name comes from the idea: “Here, I’m in this project, so let’s start at the file path to our project folder, i.e. the root folder.” Knowing this, here::here() simply takes strings that point to the location of any of our project’s files. For example, here::here(\"output\", \"data_for_table.rds\") will create a file path to the output folder ending with data_for_table.rds.\nFor example, we have a data file we want to display as a table, it will be saved somewhere in the above files with a line like write_rds(data_for_table, here(\"output\", \"data_for_table.rds\")).\nThen, in our .qmd file, we can simply add data_for_table &lt;- read_rds(here(\"output\", \"data_for_table.rds\")). Either load the readr library or prepend read_rds() with readr::.\nFinally, place the .qmd file into the qmd folder. Now we not only have a faster report, but our project is more organized."
  },
  {
    "objectID": "04-stay-organized.html#optimal-data-access-more-reliable",
    "href": "04-stay-organized.html#optimal-data-access-more-reliable",
    "title": "\n4  Review (to Stay Organized)\n",
    "section": "\n4.3 Optimal Data Access (More Reliable)",
    "text": "4.3 Optimal Data Access (More Reliable)\nIt’s a great idea to review how your getting raw data. If they are emailed .csv or .xlsx files, and especially if they have been manually edited or downloaded, there might be a better way to access data from the source. Accessing raw data from the source is more reliable and automatic. There’s less chance of a middle person between you and the data making a mistake and you having to re-run scripts with the corrections if the mistake even gets discovered! Also, you can get data without the limitations that come from waiting for a person to manage and deliver it.\nReviewing your strategy and improving it to allow for direct access may take more up-front work, but it usually will reduce future work. Another benefit is that learning to directly access data will up-skill you and further your career. You can learn software (data) engineering concepts like databases, API’s (Application Programming Interfaces), and more. These topics are beyond the scope of this book, but this section is here to encourage you to ask questions and learn more. A good book or large-language model can help introduce you to these topics. Once you become familiar with the lingo, you can start to incorporate database concepts with the following packages:\n\n\ndbplyr for lazy loading and computation (i.e. using the database server instead of your computer to hold data in memory and perform work)\n\nDBI for reading and writing to databases\n\ndm for data models (tables in your database and their relationships to each other)\n\nhttr2 for data to and from API’s"
  },
  {
    "objectID": "04-stay-organized.html#optimal-code-more-maintanable",
    "href": "04-stay-organized.html#optimal-code-more-maintanable",
    "title": "\n4  Review (to Stay Organized)\n",
    "section": "\n4.4 Optimal Code (More Maintanable)",
    "text": "4.4 Optimal Code (More Maintanable)\nMaking Your Own Functions\nLet’s say we need to read data in again, and we have named your files as per Section 2.1. To summarize, the file names have phrases with words separated by -, and multiple phrases are separated by _.\nInstead of copy-pasting the same code we used the previous time, we can avoid this repetition with a function. We can create this function by assigning function() to an object, and entering the inputs inside the () like so:\n\nsum &lt;- function(x, y) x + y\nsum(2, 2)\n\n[1] 4\n\n\nThe inputs of a function should be the parts of the function that change over repeated use. Since we want to repeat the code to read in data, but without being repetitive, our function will only contain inputs that are not repetitive. What part of reading our data is not repetitive now that we want to repeat the task for a set of different files?\nFor one, we can imagine that a new set of files might have a different number of phrases in the file names. So one input of our function can be n_phrases. Two, we can imagine that the phrases represent something different. Since we named them previously, let us call a second input of our function names_phrases.\nLastly, we need to name our function. The function name should reflect the main behavior. If it is hard to identify the main behavior, then it is probably best to split the function into multiple functions. Naming the functions appropriately is important for readability.\nLet us start by listing the behaviors of our function or functions:\n\nChoose a file\nFind the folder (directory) of this file\nFind the names of the csv files in this folder\nGet a matrix from splitting the phrases in each name\nName the columns and turn the matrix into a tibble\nFor each row representing a file, read its respective data into the tibble\n\nThat is a lot for one name to represent. Hence it is more prudent to separate these behaviors into multiple functions.\nCompare Your Functions to Others\nAlthough we could place all the code needed to read in data inside our function and name the function read_csv_in_df(), this is not a good idea. It is inconsistent with the popular function read_csv(), which has more than two arguments, the first of which is a file path. This could confuse future readers (including future you).\nWith only two arguments, our function has the form function(n_phrases, names_phrases){code}. The code it will execute is in curly brackets {}. For function(x, y) x + y, we did not need the {} curly brackets. For our new function, they will be needed as the code will have multiple lines.\nWe could place all the code needed to read in data inside and name the function read_csv_in_df():\n\nread_csv_in_df &lt;- function(n_phrases, names_phrases){\n\n  one_file_path &lt;- file.choose()\n  directory_path &lt;- one_file_path |&gt; path_dir()\n  file_names &lt;- directory_path |&gt; list.files(pattern = \"csv\")\n  file_paths &lt;- directory_path |&gt; dir_ls()\n\n  split_matrix &lt;- file_names |&gt; str_split_fixed(\"[._]\", n_phrases)\n  colnames(split_matrix) &lt;- names_phrases\n\n  df &lt;- split_matrix |&gt;\n    as_tibble() |&gt;\n    mutate(data = map(file_paths, read_csv))\n\n  df\n\n}\n\n\n# read_csv_in_df\n\n\n# read_csv_in_df(4, c(\"source\", \"country\", \"date\" ,\"file_type\"))"
  },
  {
    "objectID": "04-stay-organized.html#optimal-file-folder-structure-communicative",
    "href": "04-stay-organized.html#optimal-file-folder-structure-communicative",
    "title": "\n4  Review (to Stay Organized)\n",
    "section": "\n4.1 Optimal File-Folder Structure (Communicative)",
    "text": "4.1 Optimal File-Folder Structure (Communicative)\nWe discussed how to optimally name data files in Section 2.1. We discussed how to write a Quarto report (a .qmd file) in Chapter 1. Should these sit in the same folder? For a small project, that can be adequate. However, it’s best to organize different kinds of files into different folders. This will help prevent confusion if and when our projects become large. It can also dramatically speed up the rendering of our reports, which is covered in the next section.\nGenerally, project files should be organized into the below folders:\n\n\ndata-raw (raw data files)\n\ndata (.R files that process raw data and create clean subsets)\n\nR_analysis (.R files that create analytic results)\n\nIf reporting, you should also have the following:\n\n\noutput (outputs that will be shared or used in reports; the latter can be the final objects in R_analysis saved as .rds)\n\nqmd (.qmd files which are Quarto reports)\n\nRmd (.Rmd files which are RMarkdown reports)\n\nOptionally:\n\n\nprose (references like Word documents, text files, etc.)"
  },
  {
    "objectID": "04-stay-organized.html#optimal-reports-quickly-rendered",
    "href": "04-stay-organized.html#optimal-reports-quickly-rendered",
    "title": "\n4  Review (to Stay Organized)\n",
    "section": "\n4.2 Optimal Reports (Quickly Rendered)",
    "text": "4.2 Optimal Reports (Quickly Rendered)\nMotivation\nIn Chapter 1 we processed raw data in a Quarto document, which would go inside the qmd folder. Above we are saying that raw data should be processed in .R files inside of the data folder. Why the change?\nTo be fair, many analysts start their R journey using Quarto (or RMarkdown), including me. For Python users likewise, they often start with Jupyter. The ability to combine prose (written text), code, and outputs is beginner-friendly. It’s not, however, always computer-friendly. If code that processes data takes a moderate time to run, the report render will take at least the same amount of time. If, instead, the code takes a short amount of time to run, because it does not process data beyond simply importing it, then the report render will be much, much faster.\nMethod\nIf we want fast reports, we want to simply import data and plots. We take out the data processing parts of our .qmd file and place them into an .R file (or multiple .R files) inside a new analysis folder. We name these .R files with the same philosophy as in Section 2.1: phrases separated by _, words in phrases separated by -. With several .R files, we add 0-padded numbers to the front of the file name. Here is an example:\n\n01_merge-data.R\n02_filter-data.R\n03_plot-data.R\n04_stat-analysis.R\n\nAny objects that we need for our report are saved using readr::write_rds(). The first two arguments are the object to write, and the file path (where to write it). The object can, for example, be a data file we want to display as a table in our report. The file path is going to refer to the new output folder. The best way to refer to files in this folder is to use the here package. here::here() is the function, and its name comes from the idea: “Here, I’m in this project, so let’s start at the file path to our project folder, i.e. the root folder.” Knowing this, here::here() simply takes strings that point to the location of any of our project’s files. For example, here::here(\"output\", \"data_for_table.rds\") will create a file path to the output folder ending with data_for_table.rds.\nFor example, we have a data file we want to display as a table, it will be saved somewhere in the above files with a line like write_rds(data_for_table, here(\"output\", \"data_for_table.rds\")).\nThen, in our .qmd file, we can simply add data_for_table &lt;- read_rds(here(\"output\", \"data_for_table.rds\")). Either load the readr library or prepend read_rds() with readr::.\nFinally, place the .qmd file into the qmd folder. Now we not only have a faster report, but our project is more organized."
  },
  {
    "objectID": "04-stay-organized.html#optimal-data-access-reliable",
    "href": "04-stay-organized.html#optimal-data-access-reliable",
    "title": "\n4  Review (to Stay Organized)\n",
    "section": "\n4.3 Optimal Data Access (Reliable)",
    "text": "4.3 Optimal Data Access (Reliable)\nIt’s a great idea to review how your getting raw data. If they are emailed .csv or .xlsx files, and especially if they have been manually edited or downloaded, there might be a better way to access data from the source. Accessing raw data from the source is more reliable and automatic. There’s less chance of a middle person between you and the data making a mistake and you having to re-run scripts with the corrections if the mistake even gets discovered! Also, you can get data without the limitations that come from waiting for a person to manage and deliver it.\nReviewing your strategy and improving it to allow for direct access may take more up-front work, but it usually will reduce future work. Another benefit is that learning to directly access data will up-skill you and further your career. You can learn software (data) engineering concepts like databases, API’s (Application Programming Interfaces), and more. These topics are beyond the scope of this book, but this section is here to encourage you to ask questions and learn more. A good book or large-language model can help introduce you to these topics. Once you become familiar with the lingo, you can start to incorporate database concepts with the following packages:\n\n\ndbplyr for lazy loading and computation (i.e. using the database server instead of your computer to hold data in memory and perform work)\n\nDBI for reading and writing to databases\n\ndm for data models (tables in your database and their relationships to each other)\n\nhttr2 for data to and from API’s"
  },
  {
    "objectID": "04-stay-organized.html#optimal-code-maintanable",
    "href": "04-stay-organized.html#optimal-code-maintanable",
    "title": "\n4  Review (to Stay Organized)\n",
    "section": "\n4.4 Optimal Code (Maintanable)",
    "text": "4.4 Optimal Code (Maintanable)\nMaking Your Own Functions\nLet’s say we need to read data in again, and we have named your files as per Section 2.1. To summarize, the file names have phrases with words separated by -, and multiple phrases are separated by _.\nInstead of copy-pasting the same code we used the previous time, we can avoid this repetition with a function. We can create this function by assigning function() to an object, and entering the inputs inside the () like so:\n\nsum &lt;- function(x, y) x + y\nsum(2, 2)\n\n[1] 4\n\n\nThe inputs of a function should be the parts of the function that change over repeated use. Since we want to repeat the code to read in data, but without being repetitive, our function will only contain inputs that are not repetitive. What part of reading our data is not repetitive now that we want to repeat the task for a set of different files?\nFor one, we can imagine that a new set of files might have a different number of phrases in the file names. So one input of our function can be n_phrases. Two, we can imagine that the phrases represent something different. Since we named them previously, let us call a second input of our function names_phrases.\nLastly, we need to name our function. The function name should reflect the main behavior. If it is hard to identify the main behavior, then it is probably best to split the function into multiple functions. Naming the functions appropriately is important for readability.\nLet us start by listing the behaviors of our function or functions:\n\nChoose a file\nFind the folder (directory) of this file\nFind the names of the csv files in this folder\nGet a matrix from splitting the phrases in each name\nName the columns and turn the matrix into a tibble\nFor each row representing a file, read its respective data into the tibble\n\nThat is a lot for one name to represent. Hence it is more prudent to separate these behaviors into multiple functions.\nCompare Your Functions to Others\nAlthough we could place all the code needed to read in data inside our function and name the function read_csv_in_df(), this is not a good idea. It is inconsistent with the popular function read_csv(), which has more than two arguments, the first of which is a file path. This could confuse future readers (including future you).\nWith only two arguments, our function has the form function(n_phrases, names_phrases){code}. The code it will execute is in curly brackets {}. For function(x, y) x + y, we did not need the {} curly brackets. For our new function, they will be needed as the code will have multiple lines.\nWe could place all the code needed to read in data inside and name the function read_csv_in_df():\n\nread_csv_in_df &lt;- function(n_phrases, names_phrases){\n\n  one_file_path &lt;- file.choose()\n  directory_path &lt;- one_file_path |&gt; path_dir()\n  file_names &lt;- directory_path |&gt; list.files(pattern = \"csv\")\n  file_paths &lt;- directory_path |&gt; dir_ls()\n\n  split_matrix &lt;- file_names |&gt; str_split_fixed(\"[._]\", n_phrases)\n  colnames(split_matrix) &lt;- names_phrases\n\n  df &lt;- split_matrix |&gt;\n    as_tibble() |&gt;\n    mutate(data = map(file_paths, read_csv))\n\n  df\n\n}\n\n\n# read_csv_in_df\n\n\n# read_csv_in_df(4, c(\"source\", \"country\", \"date\" ,\"file_type\"))"
  },
  {
    "objectID": "04-stay-organized.html#optimal-file-folder-structure-explicit",
    "href": "04-stay-organized.html#optimal-file-folder-structure-explicit",
    "title": "\n4  Review (to Stay Organized)\n",
    "section": "\n4.1 Optimal File-Folder Structure (Explicit)",
    "text": "4.1 Optimal File-Folder Structure (Explicit)\nWe discussed how to optimally name data files in Section 2.1. We discussed how to write a Quarto report (a .qmd file) in Chapter 1. Should these sit in the same folder? For a small project, that can be adequate. However, it’s best to organize different kinds of files into different folders. This will help prevent confusion if and when our projects become large. It can also dramatically speed up the rendering of our reports, which is covered in the next section.\nGenerally, project files should be organized into the below folders:\n\n\ndata-raw (raw data files)\n\ndata (.R files that process raw data and create clean subsets)\n\nR_analysis (.R files that create analytic results)\n\nIf reporting, you should also have the following:\n\n\noutput (outputs that will be shared or used in reports; the latter can be the final objects in R_analysis saved as .rds)\n\nqmd (.qmd files which are Quarto reports)\n\nRmd (.Rmd files which are RMarkdown reports)\n\nOptionally:\n\n\nprose (references like Word documents, text files, etc.)"
  },
  {
    "objectID": "04-stay-organized.html#optimal-reports-quick-rendering",
    "href": "04-stay-organized.html#optimal-reports-quick-rendering",
    "title": "\n4  Review (to Stay Organized)\n",
    "section": "\n4.2 Optimal Reports (Quick Rendering)",
    "text": "4.2 Optimal Reports (Quick Rendering)\nMotivation\nIn Chapter 1 we processed raw data in a Quarto document, which would go inside the qmd folder. Above we are saying that raw data should be processed in .R files inside of the data folder. Why the change?\nTo be fair, many analysts start their R journey using Quarto (or RMarkdown), including me. For Python users likewise, they often start with Jupyter. The ability to combine prose (written text), code, and outputs is beginner-friendly. It’s not, however, always computer-friendly. If code that processes data takes a moderate time to run, the report render will take at least the same amount of time. If, instead, the code takes a short amount of time to run, because it does not process data beyond simply importing it, then the report render will be much, much faster.\nMethod\nIf we want fast reports, we want to simply import data and plots. We take out the data processing parts of our .qmd file and place them into an .R file (or multiple .R files) inside a new analysis folder. We name these .R files with the same philosophy as in Section 2.1: phrases separated by _, words in phrases separated by -. With several .R files, we add 0-padded numbers to the front of the file name. Here is an example:\n\n01_merge-data.R\n02_filter-data.R\n03_plot-data.R\n04_stat-analysis.R\n\nAny objects that we need for our report are saved using readr::write_rds(). The first two arguments are the object to write, and the file path (where to write it). The object can, for example, be a data file we want to display as a table in our report. The file path is going to refer to the new output folder. The best way to refer to files in this folder is to use the here package. here::here() is the function, and its name comes from the idea: “Here, I’m in this project, so let’s start at the file path to our project folder, i.e. the root folder.” Knowing this, here::here() simply takes strings that point to the location of any of our project’s files. For example, here::here(\"output\", \"data_for_table.rds\") will create a file path to the output folder ending with data_for_table.rds.\nFor example, we have a data file we want to display as a table, it will be saved somewhere in the above files with a line like write_rds(data_for_table, here(\"output\", \"data_for_table.rds\")).\nThen, in our .qmd file, we can simply add data_for_table &lt;- read_rds(here(\"output\", \"data_for_table.rds\")). Either load the readr library or prepend read_rds() with readr::.\nFinally, place the .qmd file into the qmd folder. Now we not only have a faster report, but our project is more organized."
  },
  {
    "objectID": "04-stay-organized.html#optimal-reports-quick-renderability",
    "href": "04-stay-organized.html#optimal-reports-quick-renderability",
    "title": "\n4  Review (to Stay Organized)\n",
    "section": "\n4.2 Optimal Reports (Quick Renderability)",
    "text": "4.2 Optimal Reports (Quick Renderability)\nMotivation\nIn Chapter 1 we processed raw data in a Quarto document, which would go inside the qmd folder. Above we are saying that raw data should be processed in .R files inside of the data folder. Why the change?\nTo be fair, many analysts start their R journey using Quarto (or RMarkdown), including me. For Python users likewise, they often start with Jupyter. The ability to combine prose (written text), code, and outputs is beginner-friendly. It’s not, however, always computer-friendly. If code that processes data takes a moderate time to run, the report render will take at least the same amount of time. If, instead, the code takes a short amount of time to run, because it does not process data beyond simply importing it, then the report render will be much, much faster.\nMethod\nIf we want fast reports, we want to simply import data and plots. We take out the data processing parts of our .qmd file and place them into an .R file (or multiple .R files) inside a new analysis folder. We name these .R files with the same philosophy as in Section 2.1: phrases separated by _, words in phrases separated by -. With several .R files, we add 0-padded numbers to the front of the file name. Here is an example:\n\n01_merge-data.R\n02_filter-data.R\n03_plot-data.R\n04_stat-analysis.R\n\nAny objects that we need for our report are saved using readr::write_rds(). The first two arguments are the object to write, and the file path (where to write it). The object can, for example, be a data file we want to display as a table in our report. The file path is going to refer to the new output folder. The best way to refer to files in this folder is to use the here package. here::here() is the function, and its name comes from the idea: “Here, I’m in this project, so let’s start at the file path to our project folder, i.e. the root folder.” Knowing this, here::here() simply takes strings that point to the location of any of our project’s files. For example, here::here(\"output\", \"data_for_table.rds\") will create a file path to the output folder ending with data_for_table.rds.\nFor example, we have a data file we want to display as a table, it will be saved somewhere in the above files with a line like write_rds(data_for_table, here(\"output\", \"data_for_table.rds\")).\nThen, in our .qmd file, we can simply add data_for_table &lt;- read_rds(here(\"output\", \"data_for_table.rds\")). Either load the readr library or prepend read_rds() with readr::.\nFinally, place the .qmd file into the qmd folder. Now we not only have a faster report, but our project is more organized."
  },
  {
    "objectID": "04-stay-organized.html#optimal-reports-fast-renderability",
    "href": "04-stay-organized.html#optimal-reports-fast-renderability",
    "title": "\n4  Review (to Stay Organized)\n",
    "section": "\n4.2 Optimal Reports (Fast Renderability)",
    "text": "4.2 Optimal Reports (Fast Renderability)\nMotivation\nIn Chapter 1 we processed raw data in a Quarto document, which would go inside the qmd folder. Above we are saying that raw data should be processed in .R files inside of the data folder. Why the change?\nTo be fair, many analysts start their R journey using Quarto (or RMarkdown), including me. For Python users likewise, they often start with Jupyter. The ability to combine prose (written text), code, and outputs is beginner-friendly. It’s not, however, always computer-friendly. If code that processes data takes a moderate time to run, the report render will take at least the same amount of time. If, instead, the code takes a short amount of time to run, because it does not process data beyond simply importing it, then the report render will be much, much faster.\nMethod\nIf we want fast reports, we want to simply import data and plots. We take out the data processing parts of our .qmd file and place them into an .R file (or multiple .R files) inside a new analysis folder. We name these .R files with the same philosophy as in Section 2.1: phrases separated by _, words in phrases separated by -. With several .R files, we add 0-padded numbers to the front of the file name. Here is an example:\n\n01_merge-data.R\n02_filter-data.R\n03_plot-data.R\n04_stat-analysis.R\n\nAny objects that we need for our report are saved using readr::write_rds(). The first two arguments are the object to write, and the file path (where to write it). The object can, for example, be a data file we want to display as a table in our report. The file path is going to refer to the new output folder. The best way to refer to files in this folder is to use the here package. here::here() is the function, and its name comes from the idea: “Here, I’m in this project, so let’s start at the file path to our project folder, i.e. the root folder.” Knowing this, here::here() simply takes strings that point to the location of any of our project’s files. For example, here::here(\"output\", \"data_for_table.rds\") will create a file path to the output folder ending with data_for_table.rds.\nFor example, we have a data file we want to display as a table, it will be saved somewhere in the above files with a line like write_rds(data_for_table, here(\"output\", \"data_for_table.rds\")).\nThen, in our .qmd file, we can simply add data_for_table &lt;- read_rds(here(\"output\", \"data_for_table.rds\")). Either load the readr library or prepend read_rds() with readr::.\nFinally, place the .qmd file into the qmd folder. Now we not only have a faster report, but our project is more organized."
  }
]